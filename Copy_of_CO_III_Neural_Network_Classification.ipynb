{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of CO III  Neural_Network_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alphageek392/MACHINE-LEARNING/blob/main/Copy_of_CO_III_Neural_Network_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhPEM4IUoDKA"
      },
      "source": [
        "# Joint Online Faculty Development programme on Deep Learning (Parallel Architecture) Aug 23 – Sep 3 , 2021\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpJe0cAaoG98"
      },
      "source": [
        "# Tutorial 3: Neural Network Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIT7QrK2PwdM"
      },
      "source": [
        "Dataset: [Pima Indian Diabetes Dataset](https://data.world/data-society/pima-indians-diabetes-database#)\n",
        "\n",
        "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective is to predict based on diagnostic measurements whether a patient has diabetes.\n",
        "\n",
        "Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n",
        "\n",
        "Attributes of PIMA dataset:\n",
        "\n",
        "**Pregnancies**: Number of times pregnant\n",
        "\n",
        "**Glucose**: Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
        "\n",
        "**BloodPressure**: Diastolic blood pressure (mm Hg)\n",
        "\n",
        "**SkinThickness**: Triceps skin fold thickness (mm)\n",
        "\n",
        "**Insulin**: 2-Hour serum insulin (mu U/ml)\n",
        "\n",
        "**BMI**: Body mass index (weight in kg/(height in m)^2)\n",
        "\n",
        "**DiabetesPedigreeFunction**: Diabetes pedigree function\n",
        "\n",
        "**Age**: Age (years)\n",
        "\n",
        "**Outcome**: Class variable (0 or 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIAgs3sTY712"
      },
      "source": [
        "**1. Mount the Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrZg_G5MQ4L5",
        "outputId": "c9b7a657-8f67-4292-f6dc-642fdf0d550d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqAhYoWHZAwg"
      },
      "source": [
        "**2. Move to the place where data resides**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjgG_3CiP4eQ",
        "outputId": "56c1dab2-b109-4360-b451-5471d16b18c0"
      },
      "source": [
        "%cd /content/drive/MyDrive"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "S-KhHH_xATY8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f172a33d-af95-4e12-bb92-ef6d4d2c88a2"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'0827CO191017-Gaurav Shardul.pdf'\n",
            " 20210806_124305_HDR.jpg\n",
            "'29th '\n",
            "'ADA Practical 0827CO191017 (1).docx'\n",
            "'ADA Practical 0827CO191017.docx'\n",
            "'ARE YOU AN ENTREPRENEUR?.gform'\n",
            " Classroom\n",
            "'Colab Notebooks'\n",
            "'COVID-9 pledge Gaurav Shardul.docx'\n",
            "'CSIT - Workshop.xlsx'\n",
            " custom_trainvalacc.png\n",
            " custom_trainvalloss.png\n",
            " diabetes.csv\n",
            " file_1.docx\n",
            " file_1.gdoc\n",
            "'Fundamental Training.pdf'\n",
            "'Gaurav Shardul- CO 17 COMP. ENGG. 3RD SEM.pdf'\n",
            "'Gaurav Shardul-(CO17).pdf'\n",
            " GDToT\n",
            "'Getting started.pdf'\n",
            " Hackerrank.png\n",
            "'IBM CAD101EN Certificate _ edX.pdf'\n",
            "'laptops (1).csv.gsheet'\n",
            " laptops.csv.gsheet\n",
            "'Meet Recordings'\n",
            " Parent_AFD_2297877_3012202010387314.pdf\n",
            "'Quiz on Innovations and Technology.gform'\n",
            "'Research Paper G1 Minor project.gdoc'\n",
            " Screenshot_20210724-134240.png\n",
            " Sharer.pw\n",
            "'Training Batch Details (1) (1).gsheet'\n",
            "'Untitled document (1).gdoc'\n",
            "'Untitled document.gdoc'\n",
            "'।। शपथ पत्र ।।(Nikita) (1).gdoc'\n",
            "'।। शपथ पत्र ।।(Nikita).gdoc'\n",
            "'।। शपथ पत्र ।।(Nikita).pdf'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "f65jHMx2I_1O"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKvfswsOZLUB"
      },
      "source": [
        "**3. Read the dataset from CSV file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "32nNonRSSaQq",
        "outputId": "a001780e-2ecb-4730-a0a6-a610bf798d59"
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('diabetes.csv')\n",
        "data.head(10)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "0            6      148             72             35        0  33.6   \n",
              "1            1       85             66             29        0  26.6   \n",
              "2            8      183             64              0        0  23.3   \n",
              "3            1       89             66             23       94  28.1   \n",
              "4            0      137             40             35      168  43.1   \n",
              "5            5      116             74              0        0  25.6   \n",
              "6            3       78             50             32       88  31.0   \n",
              "7           10      115              0              0        0  35.3   \n",
              "8            2      197             70             45      543  30.5   \n",
              "9            8      125             96              0        0   0.0   \n",
              "\n",
              "   DiabetesPedigreeFunction  Age  Outcome  \n",
              "0                     0.627   50        1  \n",
              "1                     0.351   31        0  \n",
              "2                     0.672   32        1  \n",
              "3                     0.167   21        0  \n",
              "4                     2.288   33        1  \n",
              "5                     0.201   30        0  \n",
              "6                     0.248   26        1  \n",
              "7                     0.134   29        0  \n",
              "8                     0.158   53        1  \n",
              "9                     0.232   54        1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2fa7eea3-7133-45da-922d-e728bc517050\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>116</td>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25.6</td>\n",
              "      <td>0.201</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3</td>\n",
              "      <td>78</td>\n",
              "      <td>50</td>\n",
              "      <td>32</td>\n",
              "      <td>88</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0.248</td>\n",
              "      <td>26</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>10</td>\n",
              "      <td>115</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>35.3</td>\n",
              "      <td>0.134</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2</td>\n",
              "      <td>197</td>\n",
              "      <td>70</td>\n",
              "      <td>45</td>\n",
              "      <td>543</td>\n",
              "      <td>30.5</td>\n",
              "      <td>0.158</td>\n",
              "      <td>53</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>8</td>\n",
              "      <td>125</td>\n",
              "      <td>96</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.232</td>\n",
              "      <td>54</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2fa7eea3-7133-45da-922d-e728bc517050')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2fa7eea3-7133-45da-922d-e728bc517050 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2fa7eea3-7133-45da-922d-e728bc517050');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrslDLESShr7",
        "outputId": "ab6c5601-ebb5-4db7-b260-09f84a857d3a"
      },
      "source": [
        "data.columns"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
              "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLElehZ-Skgq",
        "outputId": "e43e7fcf-7b93-486e-d2b5-140874caeaf8"
      },
      "source": [
        "data.values"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  6.   , 148.   ,  72.   , ...,   0.627,  50.   ,   1.   ],\n",
              "       [  1.   ,  85.   ,  66.   , ...,   0.351,  31.   ,   0.   ],\n",
              "       [  8.   , 183.   ,  64.   , ...,   0.672,  32.   ,   1.   ],\n",
              "       ...,\n",
              "       [  5.   , 121.   ,  72.   , ...,   0.245,  30.   ,   0.   ],\n",
              "       [  1.   , 126.   ,  60.   , ...,   0.349,  47.   ,   1.   ],\n",
              "       [  1.   ,  93.   ,  70.   , ...,   0.315,  23.   ,   0.   ]])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HnZxGc4ZQlf"
      },
      "source": [
        "**4. Store the data into input feature and label variables**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPfA5BF0Sm4R",
        "outputId": "771a194f-51d9-426e-c695-8bae7b9d56c6"
      },
      "source": [
        "dataset= data.values\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "print(X)\n",
        "print(Y)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  6.    148.     72.    ...  33.6     0.627  50.   ]\n",
            " [  1.     85.     66.    ...  26.6     0.351  31.   ]\n",
            " [  8.    183.     64.    ...  23.3     0.672  32.   ]\n",
            " ...\n",
            " [  5.    121.     72.    ...  26.2     0.245  30.   ]\n",
            " [  1.    126.     60.    ...  30.1     0.349  47.   ]\n",
            " [  1.     93.     70.    ...  30.4     0.315  23.   ]]\n",
            "[1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0.\n",
            " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0.\n",
            " 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0.\n",
            " 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1.\n",
            " 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0.\n",
            " 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1.\n",
            " 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0.\n",
            " 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
            " 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1.\n",
            " 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1.\n",
            " 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdPZerNUZV4Q"
      },
      "source": [
        "**5. Data Normalization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pM4g3T1fWri-",
        "outputId": "d4c188b9-4cba-4e45-c704-b453496b8827"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "X_scale = min_max_scaler.fit_transform(X)\n",
        "X_scale"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.35294118, 0.74371859, 0.59016393, ..., 0.50074516, 0.23441503,\n",
              "        0.48333333],\n",
              "       [0.05882353, 0.42713568, 0.54098361, ..., 0.39642325, 0.11656704,\n",
              "        0.16666667],\n",
              "       [0.47058824, 0.91959799, 0.52459016, ..., 0.34724292, 0.25362938,\n",
              "        0.18333333],\n",
              "       ...,\n",
              "       [0.29411765, 0.6080402 , 0.59016393, ..., 0.390462  , 0.07130658,\n",
              "        0.15      ],\n",
              "       [0.05882353, 0.63316583, 0.49180328, ..., 0.4485842 , 0.11571307,\n",
              "        0.43333333],\n",
              "       [0.05882353, 0.46733668, 0.57377049, ..., 0.45305514, 0.10119556,\n",
              "        0.03333333]])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1B5x8C0ZY-e"
      },
      "source": [
        "**6. One-hot vector conversion**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWPUAnA-XNd8",
        "outputId": "c9569904-2cca-427f-ed25-8dd95ffb517f"
      },
      "source": [
        "from keras.utils import np_utils\n",
        "encoded_y = np_utils.to_categorical(Y)\n",
        "encoded_y"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       ...,\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeJWmMxjZbgo"
      },
      "source": [
        "**7. Split the dataset into training, testing and validation set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BqXnV1FXYIV",
        "outputId": "83369959-52e2-41a0-a43d-a7e6b5a46b89"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_training, X_testing, Y_training, Y_testing = train_test_split(X_scale, encoded_y, test_size=0.2, random_state=10)\n",
        "X_training, X_valid, Y_training, Y_valid = train_test_split(X_training, Y_training, test_size=0.2, random_state=10)\n",
        "print(len(X_training))\n",
        "print(len(X_testing))\n",
        "print(len(X_valid))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "491\n",
            "154\n",
            "123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EH9IZizVZfKB"
      },
      "source": [
        "**8. Model Creation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNfmvbMOXeku",
        "outputId": "aa853062-d5dc-4d75-dd88-67d198abd424"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Creating the model\n",
        "model = Sequential()\n",
        "model.add(Dense(24, input_shape=(8,), activation='relu'))\n",
        "model.add(Dense(20, activation='relu'))\n",
        "model.add(Dense(16, activation='tanh'))\n",
        "model.add(Dense(12, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "model.summary()   #gives a summary of the model"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_56 (Dense)            (None, 24)                216       \n",
            "                                                                 \n",
            " dense_57 (Dense)            (None, 20)                500       \n",
            "                                                                 \n",
            " dense_58 (Dense)            (None, 16)                336       \n",
            "                                                                 \n",
            " dense_59 (Dense)            (None, 12)                204       \n",
            "                                                                 \n",
            " dense_60 (Dense)            (None, 8)                 104       \n",
            "                                                                 \n",
            " dense_61 (Dense)            (None, 2)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,378\n",
            "Trainable params: 1,378\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYxZHI_EZiEF"
      },
      "source": [
        "**9. Model Compile**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plF2qlxwXiIY"
      },
      "source": [
        "from tensorflow.keras import optimizers\n",
        "opt=optimizers.SGD(learning_rate=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8VrUFVQZkNd"
      },
      "source": [
        "**10. Model Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "if you have 1000 training examples, and your batch size is  500, then it will take 2 iterations to complete 1 epoch."
      ],
      "metadata": {
        "id": "08Ul5lN90_Sp"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhDZ8yPhXrs0",
        "outputId": "49de5e8d-1efe-4351-8cc5-055658e4793d"
      },
      "source": [
        "hist = model.fit(X_training, Y_training,batch_size=4,  epochs=800, validation_data=(X_valid,Y_valid))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/800\n",
            "123/123 [==============================] - 1s 4ms/step - loss: 0.6618 - accuracy: 0.6680 - val_loss: 0.6748 - val_accuracy: 0.6260\n",
            "Epoch 2/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6523 - accuracy: 0.6680 - val_loss: 0.6805 - val_accuracy: 0.6260\n",
            "Epoch 3/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6481 - accuracy: 0.6680 - val_loss: 0.6679 - val_accuracy: 0.6260\n",
            "Epoch 4/800\n",
            "123/123 [==============================] - 1s 4ms/step - loss: 0.6434 - accuracy: 0.6680 - val_loss: 0.6639 - val_accuracy: 0.6260\n",
            "Epoch 5/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6386 - accuracy: 0.6680 - val_loss: 0.6594 - val_accuracy: 0.6260\n",
            "Epoch 6/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6371 - accuracy: 0.6680 - val_loss: 0.6626 - val_accuracy: 0.6260\n",
            "Epoch 7/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6329 - accuracy: 0.6680 - val_loss: 0.6605 - val_accuracy: 0.6260\n",
            "Epoch 8/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6300 - accuracy: 0.6680 - val_loss: 0.6552 - val_accuracy: 0.6260\n",
            "Epoch 9/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6237 - accuracy: 0.6680 - val_loss: 0.6437 - val_accuracy: 0.6260\n",
            "Epoch 10/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.6146 - accuracy: 0.6680 - val_loss: 0.6324 - val_accuracy: 0.6260\n",
            "Epoch 11/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6047 - accuracy: 0.6680 - val_loss: 0.6199 - val_accuracy: 0.6260\n",
            "Epoch 12/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5937 - accuracy: 0.6680 - val_loss: 0.6042 - val_accuracy: 0.6260\n",
            "Epoch 13/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5793 - accuracy: 0.6680 - val_loss: 0.5879 - val_accuracy: 0.6260\n",
            "Epoch 14/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5633 - accuracy: 0.6680 - val_loss: 0.5676 - val_accuracy: 0.6260\n",
            "Epoch 15/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5492 - accuracy: 0.6680 - val_loss: 0.5787 - val_accuracy: 0.6260\n",
            "Epoch 16/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5313 - accuracy: 0.7047 - val_loss: 0.5381 - val_accuracy: 0.7317\n",
            "Epoch 17/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5219 - accuracy: 0.7393 - val_loss: 0.5625 - val_accuracy: 0.6992\n",
            "Epoch 18/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7312 - val_loss: 0.5356 - val_accuracy: 0.7805\n",
            "Epoch 19/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7495 - val_loss: 0.5323 - val_accuracy: 0.7236\n",
            "Epoch 20/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5130 - accuracy: 0.7515 - val_loss: 0.5114 - val_accuracy: 0.7480\n",
            "Epoch 21/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.7454 - val_loss: 0.5076 - val_accuracy: 0.7561\n",
            "Epoch 22/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7454 - val_loss: 0.5030 - val_accuracy: 0.7724\n",
            "Epoch 23/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4957 - accuracy: 0.7536 - val_loss: 0.5125 - val_accuracy: 0.7480\n",
            "Epoch 24/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5016 - accuracy: 0.7352 - val_loss: 0.5127 - val_accuracy: 0.7642\n",
            "Epoch 25/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4891 - accuracy: 0.7617 - val_loss: 0.4921 - val_accuracy: 0.7724\n",
            "Epoch 26/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4847 - accuracy: 0.7576 - val_loss: 0.5136 - val_accuracy: 0.7724\n",
            "Epoch 27/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4899 - accuracy: 0.7637 - val_loss: 0.5466 - val_accuracy: 0.7398\n",
            "Epoch 28/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4965 - accuracy: 0.7475 - val_loss: 0.4890 - val_accuracy: 0.7642\n",
            "Epoch 29/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4918 - accuracy: 0.7597 - val_loss: 0.4927 - val_accuracy: 0.7642\n",
            "Epoch 30/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.7454 - val_loss: 0.5031 - val_accuracy: 0.7805\n",
            "Epoch 31/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4928 - accuracy: 0.7597 - val_loss: 0.4851 - val_accuracy: 0.7642\n",
            "Epoch 32/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.7515 - val_loss: 0.5508 - val_accuracy: 0.7561\n",
            "Epoch 33/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4875 - accuracy: 0.7312 - val_loss: 0.4868 - val_accuracy: 0.7805\n",
            "Epoch 34/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.7475 - val_loss: 0.4860 - val_accuracy: 0.7561\n",
            "Epoch 35/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4874 - accuracy: 0.7576 - val_loss: 0.4967 - val_accuracy: 0.7805\n",
            "Epoch 36/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4912 - accuracy: 0.7434 - val_loss: 0.4850 - val_accuracy: 0.7724\n",
            "Epoch 37/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4819 - accuracy: 0.7495 - val_loss: 0.4835 - val_accuracy: 0.7724\n",
            "Epoch 38/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.7556 - val_loss: 0.5071 - val_accuracy: 0.8049\n",
            "Epoch 39/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4755 - accuracy: 0.7597 - val_loss: 0.4813 - val_accuracy: 0.7724\n",
            "Epoch 40/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.7658 - val_loss: 0.4819 - val_accuracy: 0.7805\n",
            "Epoch 41/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4864 - accuracy: 0.7536 - val_loss: 0.4789 - val_accuracy: 0.7724\n",
            "Epoch 42/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4834 - accuracy: 0.7576 - val_loss: 0.4781 - val_accuracy: 0.7805\n",
            "Epoch 43/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.7658 - val_loss: 0.4762 - val_accuracy: 0.7724\n",
            "Epoch 44/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.7617 - val_loss: 0.4816 - val_accuracy: 0.7886\n",
            "Epoch 45/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.7699 - val_loss: 0.4875 - val_accuracy: 0.7886\n",
            "Epoch 46/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.7678 - val_loss: 0.4926 - val_accuracy: 0.7886\n",
            "Epoch 47/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.7658 - val_loss: 0.4765 - val_accuracy: 0.7805\n",
            "Epoch 48/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.7678 - val_loss: 0.4795 - val_accuracy: 0.7967\n",
            "Epoch 49/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.7454 - val_loss: 0.4751 - val_accuracy: 0.7886\n",
            "Epoch 50/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.7841 - val_loss: 0.4758 - val_accuracy: 0.7642\n",
            "Epoch 51/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4790 - accuracy: 0.7454 - val_loss: 0.4705 - val_accuracy: 0.7967\n",
            "Epoch 52/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4662 - accuracy: 0.7556 - val_loss: 0.4794 - val_accuracy: 0.7724\n",
            "Epoch 53/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.7597 - val_loss: 0.4721 - val_accuracy: 0.7967\n",
            "Epoch 54/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.7597 - val_loss: 0.4713 - val_accuracy: 0.7967\n",
            "Epoch 55/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.7739 - val_loss: 0.4863 - val_accuracy: 0.7967\n",
            "Epoch 56/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.7536 - val_loss: 0.4845 - val_accuracy: 0.8130\n",
            "Epoch 57/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7699 - val_loss: 0.4827 - val_accuracy: 0.8049\n",
            "Epoch 58/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.7699 - val_loss: 0.4648 - val_accuracy: 0.7967\n",
            "Epoch 59/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7678 - val_loss: 0.4621 - val_accuracy: 0.8130\n",
            "Epoch 60/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7699 - val_loss: 0.4951 - val_accuracy: 0.7805\n",
            "Epoch 61/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7393 - val_loss: 0.4736 - val_accuracy: 0.8049\n",
            "Epoch 62/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7841 - val_loss: 0.5080 - val_accuracy: 0.8049\n",
            "Epoch 63/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.7637 - val_loss: 0.4658 - val_accuracy: 0.7967\n",
            "Epoch 64/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.7699 - val_loss: 0.5031 - val_accuracy: 0.8130\n",
            "Epoch 65/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7678 - val_loss: 0.5035 - val_accuracy: 0.7561\n",
            "Epoch 66/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7475 - val_loss: 0.4613 - val_accuracy: 0.8049\n",
            "Epoch 67/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7780 - val_loss: 0.5433 - val_accuracy: 0.7642\n",
            "Epoch 68/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7617 - val_loss: 0.4907 - val_accuracy: 0.7967\n",
            "Epoch 69/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7699 - val_loss: 0.4731 - val_accuracy: 0.8130\n",
            "Epoch 70/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7862 - val_loss: 0.4643 - val_accuracy: 0.8293\n",
            "Epoch 71/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.7617 - val_loss: 0.4583 - val_accuracy: 0.8130\n",
            "Epoch 72/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7719 - val_loss: 0.4845 - val_accuracy: 0.7886\n",
            "Epoch 73/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7658 - val_loss: 0.4627 - val_accuracy: 0.8211\n",
            "Epoch 74/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7739 - val_loss: 0.4609 - val_accuracy: 0.8049\n",
            "Epoch 75/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.7841 - val_loss: 0.4601 - val_accuracy: 0.7967\n",
            "Epoch 76/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7597 - val_loss: 0.4821 - val_accuracy: 0.7886\n",
            "Epoch 77/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7780 - val_loss: 0.4574 - val_accuracy: 0.8049\n",
            "Epoch 78/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.7760 - val_loss: 0.4553 - val_accuracy: 0.8130\n",
            "Epoch 79/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7739 - val_loss: 0.4668 - val_accuracy: 0.8211\n",
            "Epoch 80/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7617 - val_loss: 0.4576 - val_accuracy: 0.8130\n",
            "Epoch 81/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4606 - accuracy: 0.7699 - val_loss: 0.4623 - val_accuracy: 0.8130\n",
            "Epoch 82/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.7760 - val_loss: 0.4550 - val_accuracy: 0.8211\n",
            "Epoch 83/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.7617 - val_loss: 0.4627 - val_accuracy: 0.7967\n",
            "Epoch 84/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7739 - val_loss: 0.4903 - val_accuracy: 0.7967\n",
            "Epoch 85/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.7678 - val_loss: 0.4862 - val_accuracy: 0.7886\n",
            "Epoch 86/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7637 - val_loss: 0.4716 - val_accuracy: 0.7967\n",
            "Epoch 87/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4582 - accuracy: 0.7760 - val_loss: 0.4600 - val_accuracy: 0.8130\n",
            "Epoch 88/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.7617 - val_loss: 0.4618 - val_accuracy: 0.8049\n",
            "Epoch 89/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7760 - val_loss: 0.4632 - val_accuracy: 0.8049\n",
            "Epoch 90/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.7902 - val_loss: 0.4593 - val_accuracy: 0.7886\n",
            "Epoch 91/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4514 - accuracy: 0.7739 - val_loss: 0.4819 - val_accuracy: 0.7886\n",
            "Epoch 92/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7678 - val_loss: 0.4705 - val_accuracy: 0.7886\n",
            "Epoch 93/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7923 - val_loss: 0.4580 - val_accuracy: 0.8130\n",
            "Epoch 94/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.7699 - val_loss: 0.4741 - val_accuracy: 0.7886\n",
            "Epoch 95/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7760 - val_loss: 0.4523 - val_accuracy: 0.8211\n",
            "Epoch 96/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7699 - val_loss: 0.4604 - val_accuracy: 0.8049\n",
            "Epoch 97/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.7739 - val_loss: 0.4581 - val_accuracy: 0.8049\n",
            "Epoch 98/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4476 - accuracy: 0.7780 - val_loss: 0.4609 - val_accuracy: 0.8374\n",
            "Epoch 99/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.7821 - val_loss: 0.5271 - val_accuracy: 0.7236\n",
            "Epoch 100/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.7780 - val_loss: 0.4595 - val_accuracy: 0.8211\n",
            "Epoch 101/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.7739 - val_loss: 0.4734 - val_accuracy: 0.7886\n",
            "Epoch 102/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7576 - val_loss: 0.4570 - val_accuracy: 0.8130\n",
            "Epoch 103/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.7800 - val_loss: 0.4671 - val_accuracy: 0.7886\n",
            "Epoch 104/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.7719 - val_loss: 0.4575 - val_accuracy: 0.8049\n",
            "Epoch 105/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.7739 - val_loss: 0.4862 - val_accuracy: 0.7886\n",
            "Epoch 106/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7902 - val_loss: 0.4677 - val_accuracy: 0.8049\n",
            "Epoch 107/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.7637 - val_loss: 0.4613 - val_accuracy: 0.8049\n",
            "Epoch 108/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.7902 - val_loss: 0.4931 - val_accuracy: 0.7886\n",
            "Epoch 109/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7902 - val_loss: 0.4643 - val_accuracy: 0.7967\n",
            "Epoch 110/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.7760 - val_loss: 0.4617 - val_accuracy: 0.7967\n",
            "Epoch 111/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.7882 - val_loss: 0.4543 - val_accuracy: 0.8130\n",
            "Epoch 112/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.7821 - val_loss: 0.4565 - val_accuracy: 0.8049\n",
            "Epoch 113/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7760 - val_loss: 0.4708 - val_accuracy: 0.7886\n",
            "Epoch 114/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.7862 - val_loss: 0.4524 - val_accuracy: 0.8049\n",
            "Epoch 115/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.7821 - val_loss: 0.4530 - val_accuracy: 0.8130\n",
            "Epoch 116/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7719 - val_loss: 0.5295 - val_accuracy: 0.7805\n",
            "Epoch 117/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7862 - val_loss: 0.4693 - val_accuracy: 0.7886\n",
            "Epoch 118/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.7800 - val_loss: 0.4606 - val_accuracy: 0.7967\n",
            "Epoch 119/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.7862 - val_loss: 0.4712 - val_accuracy: 0.7886\n",
            "Epoch 120/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7800 - val_loss: 0.5616 - val_accuracy: 0.8049\n",
            "Epoch 121/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.7699 - val_loss: 0.4610 - val_accuracy: 0.7967\n",
            "Epoch 122/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.7841 - val_loss: 0.4514 - val_accuracy: 0.8130\n",
            "Epoch 123/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.7923 - val_loss: 0.4599 - val_accuracy: 0.8130\n",
            "Epoch 124/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7943 - val_loss: 0.4666 - val_accuracy: 0.8049\n",
            "Epoch 125/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7902 - val_loss: 0.4528 - val_accuracy: 0.8211\n",
            "Epoch 126/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.7841 - val_loss: 0.4558 - val_accuracy: 0.8211\n",
            "Epoch 127/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.7943 - val_loss: 0.4797 - val_accuracy: 0.7886\n",
            "Epoch 128/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7719 - val_loss: 0.4624 - val_accuracy: 0.8130\n",
            "Epoch 129/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.7739 - val_loss: 0.5006 - val_accuracy: 0.7642\n",
            "Epoch 130/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4400 - accuracy: 0.7923 - val_loss: 0.4564 - val_accuracy: 0.7886\n",
            "Epoch 131/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.7841 - val_loss: 0.4712 - val_accuracy: 0.7886\n",
            "Epoch 132/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7739 - val_loss: 0.4485 - val_accuracy: 0.8130\n",
            "Epoch 133/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7800 - val_loss: 0.4510 - val_accuracy: 0.8130\n",
            "Epoch 134/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4359 - accuracy: 0.7821 - val_loss: 0.4699 - val_accuracy: 0.7967\n",
            "Epoch 135/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7963 - val_loss: 0.5219 - val_accuracy: 0.7317\n",
            "Epoch 136/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7923 - val_loss: 0.4514 - val_accuracy: 0.8211\n",
            "Epoch 137/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7902 - val_loss: 0.4593 - val_accuracy: 0.8211\n",
            "Epoch 138/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7841 - val_loss: 0.4702 - val_accuracy: 0.7886\n",
            "Epoch 139/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7780 - val_loss: 0.4952 - val_accuracy: 0.7886\n",
            "Epoch 140/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7800 - val_loss: 0.4593 - val_accuracy: 0.8211\n",
            "Epoch 141/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4416 - accuracy: 0.7800 - val_loss: 0.4540 - val_accuracy: 0.8293\n",
            "Epoch 142/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.7943 - val_loss: 0.4638 - val_accuracy: 0.8130\n",
            "Epoch 143/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.7902 - val_loss: 0.4569 - val_accuracy: 0.8211\n",
            "Epoch 144/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4304 - accuracy: 0.7739 - val_loss: 0.4680 - val_accuracy: 0.7967\n",
            "Epoch 145/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7821 - val_loss: 0.5162 - val_accuracy: 0.8049\n",
            "Epoch 146/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.8004 - val_loss: 0.4618 - val_accuracy: 0.7967\n",
            "Epoch 147/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4327 - accuracy: 0.7963 - val_loss: 0.5228 - val_accuracy: 0.7805\n",
            "Epoch 148/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7984 - val_loss: 0.4925 - val_accuracy: 0.7967\n",
            "Epoch 149/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7943 - val_loss: 0.4924 - val_accuracy: 0.7967\n",
            "Epoch 150/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7902 - val_loss: 0.4793 - val_accuracy: 0.7642\n",
            "Epoch 151/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7862 - val_loss: 0.4581 - val_accuracy: 0.8211\n",
            "Epoch 152/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7963 - val_loss: 0.5045 - val_accuracy: 0.7886\n",
            "Epoch 153/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4359 - accuracy: 0.7963 - val_loss: 0.4642 - val_accuracy: 0.8130\n",
            "Epoch 154/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.8065 - val_loss: 0.4572 - val_accuracy: 0.8130\n",
            "Epoch 155/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7862 - val_loss: 0.4611 - val_accuracy: 0.7967\n",
            "Epoch 156/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7923 - val_loss: 0.4709 - val_accuracy: 0.8130\n",
            "Epoch 157/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7984 - val_loss: 0.4574 - val_accuracy: 0.8293\n",
            "Epoch 158/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7821 - val_loss: 0.4526 - val_accuracy: 0.8130\n",
            "Epoch 159/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.7902 - val_loss: 0.4593 - val_accuracy: 0.8211\n",
            "Epoch 160/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4234 - accuracy: 0.8065 - val_loss: 0.4749 - val_accuracy: 0.8130\n",
            "Epoch 161/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.8045 - val_loss: 0.4745 - val_accuracy: 0.7967\n",
            "Epoch 162/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.7902 - val_loss: 0.4617 - val_accuracy: 0.7805\n",
            "Epoch 163/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.7923 - val_loss: 0.4798 - val_accuracy: 0.8049\n",
            "Epoch 164/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4195 - accuracy: 0.7862 - val_loss: 0.4679 - val_accuracy: 0.7886\n",
            "Epoch 165/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.8065 - val_loss: 0.5414 - val_accuracy: 0.7561\n",
            "Epoch 166/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7780 - val_loss: 0.4651 - val_accuracy: 0.7886\n",
            "Epoch 167/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.8004 - val_loss: 0.4545 - val_accuracy: 0.8130\n",
            "Epoch 168/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7984 - val_loss: 0.4632 - val_accuracy: 0.8049\n",
            "Epoch 169/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.7963 - val_loss: 0.4653 - val_accuracy: 0.8049\n",
            "Epoch 170/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.8126 - val_loss: 0.4821 - val_accuracy: 0.7642\n",
            "Epoch 171/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.7984 - val_loss: 0.4596 - val_accuracy: 0.8049\n",
            "Epoch 172/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.8024 - val_loss: 0.4786 - val_accuracy: 0.7886\n",
            "Epoch 173/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4105 - accuracy: 0.7984 - val_loss: 0.4920 - val_accuracy: 0.7805\n",
            "Epoch 174/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4092 - accuracy: 0.8024 - val_loss: 0.4753 - val_accuracy: 0.7967\n",
            "Epoch 175/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.7943 - val_loss: 0.4570 - val_accuracy: 0.8130\n",
            "Epoch 176/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4185 - accuracy: 0.7984 - val_loss: 0.4600 - val_accuracy: 0.7967\n",
            "Epoch 177/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4162 - accuracy: 0.8045 - val_loss: 0.4708 - val_accuracy: 0.8049\n",
            "Epoch 178/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4156 - accuracy: 0.7963 - val_loss: 0.4626 - val_accuracy: 0.7967\n",
            "Epoch 179/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4136 - accuracy: 0.8045 - val_loss: 0.5165 - val_accuracy: 0.7724\n",
            "Epoch 180/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4203 - accuracy: 0.7943 - val_loss: 0.4633 - val_accuracy: 0.7805\n",
            "Epoch 181/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4270 - accuracy: 0.7882 - val_loss: 0.4677 - val_accuracy: 0.7805\n",
            "Epoch 182/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.8086 - val_loss: 0.4682 - val_accuracy: 0.7886\n",
            "Epoch 183/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.8045 - val_loss: 0.4654 - val_accuracy: 0.7967\n",
            "Epoch 184/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.8228 - val_loss: 0.4821 - val_accuracy: 0.7805\n",
            "Epoch 185/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4089 - accuracy: 0.7963 - val_loss: 0.4759 - val_accuracy: 0.7805\n",
            "Epoch 186/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4107 - accuracy: 0.8167 - val_loss: 0.4800 - val_accuracy: 0.7724\n",
            "Epoch 187/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4154 - accuracy: 0.8004 - val_loss: 0.4750 - val_accuracy: 0.7805\n",
            "Epoch 188/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4083 - accuracy: 0.8147 - val_loss: 0.5618 - val_accuracy: 0.7561\n",
            "Epoch 189/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4094 - accuracy: 0.8045 - val_loss: 0.5137 - val_accuracy: 0.7480\n",
            "Epoch 190/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3990 - accuracy: 0.8208 - val_loss: 0.5017 - val_accuracy: 0.7642\n",
            "Epoch 191/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4144 - accuracy: 0.8004 - val_loss: 0.5094 - val_accuracy: 0.7561\n",
            "Epoch 192/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4037 - accuracy: 0.8045 - val_loss: 0.4742 - val_accuracy: 0.8049\n",
            "Epoch 193/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3945 - accuracy: 0.8065 - val_loss: 0.4812 - val_accuracy: 0.8049\n",
            "Epoch 194/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4058 - accuracy: 0.8086 - val_loss: 0.4621 - val_accuracy: 0.7886\n",
            "Epoch 195/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4093 - accuracy: 0.8065 - val_loss: 0.4658 - val_accuracy: 0.8130\n",
            "Epoch 196/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4030 - accuracy: 0.8147 - val_loss: 0.4979 - val_accuracy: 0.7724\n",
            "Epoch 197/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4097 - accuracy: 0.8147 - val_loss: 0.4974 - val_accuracy: 0.7724\n",
            "Epoch 198/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4064 - accuracy: 0.8126 - val_loss: 0.4683 - val_accuracy: 0.7805\n",
            "Epoch 199/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4062 - accuracy: 0.8248 - val_loss: 0.4509 - val_accuracy: 0.8293\n",
            "Epoch 200/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4022 - accuracy: 0.8187 - val_loss: 0.4801 - val_accuracy: 0.7805\n",
            "Epoch 201/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4040 - accuracy: 0.8147 - val_loss: 0.4749 - val_accuracy: 0.7886\n",
            "Epoch 202/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4022 - accuracy: 0.8248 - val_loss: 0.5082 - val_accuracy: 0.7805\n",
            "Epoch 203/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4035 - accuracy: 0.8371 - val_loss: 0.4886 - val_accuracy: 0.8049\n",
            "Epoch 204/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3941 - accuracy: 0.8248 - val_loss: 0.5052 - val_accuracy: 0.7642\n",
            "Epoch 205/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3893 - accuracy: 0.8167 - val_loss: 0.4927 - val_accuracy: 0.7805\n",
            "Epoch 206/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4077 - accuracy: 0.8167 - val_loss: 0.4835 - val_accuracy: 0.7724\n",
            "Epoch 207/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3991 - accuracy: 0.8065 - val_loss: 0.4402 - val_accuracy: 0.8049\n",
            "Epoch 208/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4018 - accuracy: 0.8228 - val_loss: 0.4740 - val_accuracy: 0.7967\n",
            "Epoch 209/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3934 - accuracy: 0.8167 - val_loss: 0.4728 - val_accuracy: 0.7642\n",
            "Epoch 210/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4038 - accuracy: 0.7984 - val_loss: 0.4533 - val_accuracy: 0.8130\n",
            "Epoch 211/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3850 - accuracy: 0.8106 - val_loss: 0.5585 - val_accuracy: 0.7805\n",
            "Epoch 212/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3915 - accuracy: 0.8269 - val_loss: 0.4833 - val_accuracy: 0.7805\n",
            "Epoch 213/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3949 - accuracy: 0.8371 - val_loss: 0.4885 - val_accuracy: 0.8130\n",
            "Epoch 214/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3969 - accuracy: 0.8065 - val_loss: 0.4734 - val_accuracy: 0.8049\n",
            "Epoch 215/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3938 - accuracy: 0.8228 - val_loss: 0.4971 - val_accuracy: 0.7398\n",
            "Epoch 216/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3972 - accuracy: 0.8065 - val_loss: 0.4654 - val_accuracy: 0.7805\n",
            "Epoch 217/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4011 - accuracy: 0.8045 - val_loss: 0.5051 - val_accuracy: 0.7724\n",
            "Epoch 218/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3958 - accuracy: 0.8248 - val_loss: 0.4763 - val_accuracy: 0.7724\n",
            "Epoch 219/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3927 - accuracy: 0.8187 - val_loss: 0.4915 - val_accuracy: 0.7561\n",
            "Epoch 220/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3926 - accuracy: 0.8228 - val_loss: 0.6186 - val_accuracy: 0.7398\n",
            "Epoch 221/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3914 - accuracy: 0.8432 - val_loss: 0.4747 - val_accuracy: 0.7805\n",
            "Epoch 222/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3931 - accuracy: 0.8004 - val_loss: 0.5775 - val_accuracy: 0.7480\n",
            "Epoch 223/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.4015 - accuracy: 0.8024 - val_loss: 0.4828 - val_accuracy: 0.7724\n",
            "Epoch 224/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3913 - accuracy: 0.8045 - val_loss: 0.4535 - val_accuracy: 0.7967\n",
            "Epoch 225/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3908 - accuracy: 0.8289 - val_loss: 0.4935 - val_accuracy: 0.7805\n",
            "Epoch 226/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3910 - accuracy: 0.8187 - val_loss: 0.4816 - val_accuracy: 0.8049\n",
            "Epoch 227/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3917 - accuracy: 0.8106 - val_loss: 0.4929 - val_accuracy: 0.7317\n",
            "Epoch 228/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3901 - accuracy: 0.8126 - val_loss: 0.5009 - val_accuracy: 0.7886\n",
            "Epoch 229/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3844 - accuracy: 0.8371 - val_loss: 0.4835 - val_accuracy: 0.8049\n",
            "Epoch 230/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3831 - accuracy: 0.8330 - val_loss: 0.4971 - val_accuracy: 0.7724\n",
            "Epoch 231/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3853 - accuracy: 0.8147 - val_loss: 0.5113 - val_accuracy: 0.7480\n",
            "Epoch 232/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3930 - accuracy: 0.8065 - val_loss: 0.4834 - val_accuracy: 0.7724\n",
            "Epoch 233/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3892 - accuracy: 0.8248 - val_loss: 0.4829 - val_accuracy: 0.7724\n",
            "Epoch 234/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3861 - accuracy: 0.8248 - val_loss: 0.4889 - val_accuracy: 0.7967\n",
            "Epoch 235/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3971 - accuracy: 0.8045 - val_loss: 0.4863 - val_accuracy: 0.7724\n",
            "Epoch 236/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3897 - accuracy: 0.8106 - val_loss: 0.4903 - val_accuracy: 0.7805\n",
            "Epoch 237/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3897 - accuracy: 0.8310 - val_loss: 0.4991 - val_accuracy: 0.7805\n",
            "Epoch 238/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3833 - accuracy: 0.8269 - val_loss: 0.5062 - val_accuracy: 0.7724\n",
            "Epoch 239/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3840 - accuracy: 0.8045 - val_loss: 0.4971 - val_accuracy: 0.7805\n",
            "Epoch 240/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3882 - accuracy: 0.8310 - val_loss: 0.4817 - val_accuracy: 0.7805\n",
            "Epoch 241/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3775 - accuracy: 0.8167 - val_loss: 0.4798 - val_accuracy: 0.8049\n",
            "Epoch 242/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3822 - accuracy: 0.8208 - val_loss: 0.4855 - val_accuracy: 0.7967\n",
            "Epoch 243/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3775 - accuracy: 0.8391 - val_loss: 0.5484 - val_accuracy: 0.7236\n",
            "Epoch 244/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3905 - accuracy: 0.8147 - val_loss: 0.4577 - val_accuracy: 0.7886\n",
            "Epoch 245/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3682 - accuracy: 0.8269 - val_loss: 0.4886 - val_accuracy: 0.8049\n",
            "Epoch 246/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3930 - accuracy: 0.8350 - val_loss: 0.4652 - val_accuracy: 0.7967\n",
            "Epoch 247/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3655 - accuracy: 0.8411 - val_loss: 0.5119 - val_accuracy: 0.7724\n",
            "Epoch 248/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3745 - accuracy: 0.8228 - val_loss: 0.5065 - val_accuracy: 0.7886\n",
            "Epoch 249/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3850 - accuracy: 0.8187 - val_loss: 0.4818 - val_accuracy: 0.7805\n",
            "Epoch 250/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3662 - accuracy: 0.8432 - val_loss: 0.5013 - val_accuracy: 0.7886\n",
            "Epoch 251/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3891 - accuracy: 0.8187 - val_loss: 0.4834 - val_accuracy: 0.7805\n",
            "Epoch 252/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3767 - accuracy: 0.8310 - val_loss: 0.4891 - val_accuracy: 0.7805\n",
            "Epoch 253/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3794 - accuracy: 0.8208 - val_loss: 0.4992 - val_accuracy: 0.7805\n",
            "Epoch 254/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3740 - accuracy: 0.8208 - val_loss: 0.4798 - val_accuracy: 0.8049\n",
            "Epoch 255/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3651 - accuracy: 0.8269 - val_loss: 0.6322 - val_accuracy: 0.7398\n",
            "Epoch 256/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3744 - accuracy: 0.8248 - val_loss: 0.4699 - val_accuracy: 0.8049\n",
            "Epoch 257/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3707 - accuracy: 0.8371 - val_loss: 0.5058 - val_accuracy: 0.7805\n",
            "Epoch 258/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3749 - accuracy: 0.8289 - val_loss: 0.5192 - val_accuracy: 0.7642\n",
            "Epoch 259/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3782 - accuracy: 0.8330 - val_loss: 0.5038 - val_accuracy: 0.7805\n",
            "Epoch 260/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3763 - accuracy: 0.8167 - val_loss: 0.4883 - val_accuracy: 0.7967\n",
            "Epoch 261/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3585 - accuracy: 0.8350 - val_loss: 0.5239 - val_accuracy: 0.7967\n",
            "Epoch 262/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8310 - val_loss: 0.4782 - val_accuracy: 0.7724\n",
            "Epoch 263/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3831 - accuracy: 0.8126 - val_loss: 0.4505 - val_accuracy: 0.8211\n",
            "Epoch 264/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3700 - accuracy: 0.8330 - val_loss: 0.5293 - val_accuracy: 0.8049\n",
            "Epoch 265/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3828 - accuracy: 0.8310 - val_loss: 0.4883 - val_accuracy: 0.8211\n",
            "Epoch 266/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3687 - accuracy: 0.8310 - val_loss: 0.5441 - val_accuracy: 0.7724\n",
            "Epoch 267/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3743 - accuracy: 0.8310 - val_loss: 0.4706 - val_accuracy: 0.8049\n",
            "Epoch 268/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3659 - accuracy: 0.8330 - val_loss: 0.4436 - val_accuracy: 0.7967\n",
            "Epoch 269/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3654 - accuracy: 0.8452 - val_loss: 0.5189 - val_accuracy: 0.7724\n",
            "Epoch 270/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3746 - accuracy: 0.8350 - val_loss: 0.4835 - val_accuracy: 0.7967\n",
            "Epoch 271/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3453 - accuracy: 0.8473 - val_loss: 0.4898 - val_accuracy: 0.7642\n",
            "Epoch 272/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3706 - accuracy: 0.8350 - val_loss: 0.4980 - val_accuracy: 0.7642\n",
            "Epoch 273/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3590 - accuracy: 0.8330 - val_loss: 0.4889 - val_accuracy: 0.7886\n",
            "Epoch 274/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3697 - accuracy: 0.8208 - val_loss: 0.5222 - val_accuracy: 0.7642\n",
            "Epoch 275/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3641 - accuracy: 0.8411 - val_loss: 0.4893 - val_accuracy: 0.7886\n",
            "Epoch 276/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3769 - accuracy: 0.8289 - val_loss: 0.4760 - val_accuracy: 0.8049\n",
            "Epoch 277/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3560 - accuracy: 0.8248 - val_loss: 0.5013 - val_accuracy: 0.7967\n",
            "Epoch 278/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3672 - accuracy: 0.8350 - val_loss: 0.5019 - val_accuracy: 0.8049\n",
            "Epoch 279/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3566 - accuracy: 0.8534 - val_loss: 0.4860 - val_accuracy: 0.7886\n",
            "Epoch 280/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3584 - accuracy: 0.8208 - val_loss: 0.4733 - val_accuracy: 0.8049\n",
            "Epoch 281/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3521 - accuracy: 0.8350 - val_loss: 0.5080 - val_accuracy: 0.7967\n",
            "Epoch 282/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3575 - accuracy: 0.8411 - val_loss: 0.5334 - val_accuracy: 0.7805\n",
            "Epoch 283/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3587 - accuracy: 0.8411 - val_loss: 0.5487 - val_accuracy: 0.7480\n",
            "Epoch 284/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3625 - accuracy: 0.8432 - val_loss: 0.4922 - val_accuracy: 0.7805\n",
            "Epoch 285/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8289 - val_loss: 0.5083 - val_accuracy: 0.7724\n",
            "Epoch 286/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3600 - accuracy: 0.8350 - val_loss: 0.5178 - val_accuracy: 0.7886\n",
            "Epoch 287/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3669 - accuracy: 0.8248 - val_loss: 0.5149 - val_accuracy: 0.7967\n",
            "Epoch 288/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3607 - accuracy: 0.8269 - val_loss: 0.4972 - val_accuracy: 0.7967\n",
            "Epoch 289/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3641 - accuracy: 0.8554 - val_loss: 0.5093 - val_accuracy: 0.7886\n",
            "Epoch 290/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3600 - accuracy: 0.8330 - val_loss: 0.4878 - val_accuracy: 0.8049\n",
            "Epoch 291/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3577 - accuracy: 0.8187 - val_loss: 0.4846 - val_accuracy: 0.8130\n",
            "Epoch 292/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3594 - accuracy: 0.8391 - val_loss: 0.4738 - val_accuracy: 0.7886\n",
            "Epoch 293/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3587 - accuracy: 0.8330 - val_loss: 0.4657 - val_accuracy: 0.8130\n",
            "Epoch 294/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3577 - accuracy: 0.8452 - val_loss: 0.5052 - val_accuracy: 0.7805\n",
            "Epoch 295/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3554 - accuracy: 0.8289 - val_loss: 0.4993 - val_accuracy: 0.7805\n",
            "Epoch 296/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3467 - accuracy: 0.8452 - val_loss: 0.4922 - val_accuracy: 0.7805\n",
            "Epoch 297/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3524 - accuracy: 0.8452 - val_loss: 0.5257 - val_accuracy: 0.7886\n",
            "Epoch 298/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3420 - accuracy: 0.8534 - val_loss: 0.5184 - val_accuracy: 0.7805\n",
            "Epoch 299/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3588 - accuracy: 0.8289 - val_loss: 0.4923 - val_accuracy: 0.7967\n",
            "Epoch 300/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3592 - accuracy: 0.8350 - val_loss: 0.4934 - val_accuracy: 0.7886\n",
            "Epoch 301/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3432 - accuracy: 0.8635 - val_loss: 0.4899 - val_accuracy: 0.7886\n",
            "Epoch 302/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3618 - accuracy: 0.8310 - val_loss: 0.4939 - val_accuracy: 0.8049\n",
            "Epoch 303/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3520 - accuracy: 0.8350 - val_loss: 0.4985 - val_accuracy: 0.7886\n",
            "Epoch 304/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8310 - val_loss: 0.4922 - val_accuracy: 0.7967\n",
            "Epoch 305/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3492 - accuracy: 0.8452 - val_loss: 0.4797 - val_accuracy: 0.7967\n",
            "Epoch 306/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3623 - accuracy: 0.8310 - val_loss: 0.5265 - val_accuracy: 0.7805\n",
            "Epoch 307/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3557 - accuracy: 0.8330 - val_loss: 0.5174 - val_accuracy: 0.7724\n",
            "Epoch 308/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3530 - accuracy: 0.8330 - val_loss: 0.5228 - val_accuracy: 0.7724\n",
            "Epoch 309/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3435 - accuracy: 0.8554 - val_loss: 0.5172 - val_accuracy: 0.7724\n",
            "Epoch 310/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3478 - accuracy: 0.8473 - val_loss: 0.5161 - val_accuracy: 0.7642\n",
            "Epoch 311/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3502 - accuracy: 0.8411 - val_loss: 0.5168 - val_accuracy: 0.7724\n",
            "Epoch 312/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3426 - accuracy: 0.8534 - val_loss: 0.5253 - val_accuracy: 0.7805\n",
            "Epoch 313/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3435 - accuracy: 0.8371 - val_loss: 0.5311 - val_accuracy: 0.8049\n",
            "Epoch 314/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3458 - accuracy: 0.8513 - val_loss: 0.5104 - val_accuracy: 0.8130\n",
            "Epoch 315/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3515 - accuracy: 0.8554 - val_loss: 0.5647 - val_accuracy: 0.7967\n",
            "Epoch 316/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3508 - accuracy: 0.8513 - val_loss: 0.5293 - val_accuracy: 0.7561\n",
            "Epoch 317/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3602 - accuracy: 0.8473 - val_loss: 0.5540 - val_accuracy: 0.7805\n",
            "Epoch 318/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3526 - accuracy: 0.8350 - val_loss: 0.4884 - val_accuracy: 0.7886\n",
            "Epoch 319/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3430 - accuracy: 0.8534 - val_loss: 0.5125 - val_accuracy: 0.7886\n",
            "Epoch 320/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3563 - accuracy: 0.8391 - val_loss: 0.5236 - val_accuracy: 0.7886\n",
            "Epoch 321/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3625 - accuracy: 0.8350 - val_loss: 0.4811 - val_accuracy: 0.7886\n",
            "Epoch 322/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3395 - accuracy: 0.8554 - val_loss: 0.5780 - val_accuracy: 0.7236\n",
            "Epoch 323/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3466 - accuracy: 0.8269 - val_loss: 0.5093 - val_accuracy: 0.8130\n",
            "Epoch 324/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3439 - accuracy: 0.8411 - val_loss: 0.4859 - val_accuracy: 0.8130\n",
            "Epoch 325/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3574 - accuracy: 0.8310 - val_loss: 0.4734 - val_accuracy: 0.8130\n",
            "Epoch 326/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3362 - accuracy: 0.8452 - val_loss: 0.4876 - val_accuracy: 0.7805\n",
            "Epoch 327/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3373 - accuracy: 0.8554 - val_loss: 0.4487 - val_accuracy: 0.8374\n",
            "Epoch 328/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3355 - accuracy: 0.8493 - val_loss: 0.4961 - val_accuracy: 0.7967\n",
            "Epoch 329/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3364 - accuracy: 0.8635 - val_loss: 0.5046 - val_accuracy: 0.7967\n",
            "Epoch 330/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3482 - accuracy: 0.8473 - val_loss: 0.5435 - val_accuracy: 0.7561\n",
            "Epoch 331/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3379 - accuracy: 0.8574 - val_loss: 0.5160 - val_accuracy: 0.7805\n",
            "Epoch 332/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3170 - accuracy: 0.8819 - val_loss: 0.4898 - val_accuracy: 0.8211\n",
            "Epoch 333/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3470 - accuracy: 0.8473 - val_loss: 0.5540 - val_accuracy: 0.7724\n",
            "Epoch 334/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3384 - accuracy: 0.8350 - val_loss: 0.5045 - val_accuracy: 0.8049\n",
            "Epoch 335/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3409 - accuracy: 0.8411 - val_loss: 0.5832 - val_accuracy: 0.7724\n",
            "Epoch 336/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3406 - accuracy: 0.8411 - val_loss: 0.5432 - val_accuracy: 0.7805\n",
            "Epoch 337/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3427 - accuracy: 0.8493 - val_loss: 0.5375 - val_accuracy: 0.7967\n",
            "Epoch 338/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.8493 - val_loss: 0.4927 - val_accuracy: 0.7724\n",
            "Epoch 339/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3358 - accuracy: 0.8493 - val_loss: 0.5149 - val_accuracy: 0.7886\n",
            "Epoch 340/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3412 - accuracy: 0.8411 - val_loss: 0.5658 - val_accuracy: 0.7805\n",
            "Epoch 341/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3297 - accuracy: 0.8432 - val_loss: 0.5214 - val_accuracy: 0.7805\n",
            "Epoch 342/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3474 - accuracy: 0.8432 - val_loss: 0.5174 - val_accuracy: 0.7642\n",
            "Epoch 343/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3457 - accuracy: 0.8391 - val_loss: 0.5060 - val_accuracy: 0.7967\n",
            "Epoch 344/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3239 - accuracy: 0.8574 - val_loss: 0.5320 - val_accuracy: 0.7724\n",
            "Epoch 345/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3362 - accuracy: 0.8330 - val_loss: 0.5722 - val_accuracy: 0.7724\n",
            "Epoch 346/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3159 - accuracy: 0.8513 - val_loss: 0.4907 - val_accuracy: 0.7967\n",
            "Epoch 347/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3349 - accuracy: 0.8534 - val_loss: 0.4944 - val_accuracy: 0.7886\n",
            "Epoch 348/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.8656 - val_loss: 0.5248 - val_accuracy: 0.8049\n",
            "Epoch 349/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3278 - accuracy: 0.8554 - val_loss: 0.4961 - val_accuracy: 0.8130\n",
            "Epoch 350/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3456 - accuracy: 0.8411 - val_loss: 0.4887 - val_accuracy: 0.8049\n",
            "Epoch 351/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3274 - accuracy: 0.8452 - val_loss: 0.4756 - val_accuracy: 0.8049\n",
            "Epoch 352/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3386 - accuracy: 0.8452 - val_loss: 0.5124 - val_accuracy: 0.7967\n",
            "Epoch 353/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3351 - accuracy: 0.8554 - val_loss: 0.5259 - val_accuracy: 0.8049\n",
            "Epoch 354/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3250 - accuracy: 0.8452 - val_loss: 0.5633 - val_accuracy: 0.7805\n",
            "Epoch 355/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3258 - accuracy: 0.8574 - val_loss: 0.4942 - val_accuracy: 0.7886\n",
            "Epoch 356/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3223 - accuracy: 0.8391 - val_loss: 0.5597 - val_accuracy: 0.7561\n",
            "Epoch 357/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3316 - accuracy: 0.8493 - val_loss: 0.6053 - val_accuracy: 0.7561\n",
            "Epoch 358/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3354 - accuracy: 0.8595 - val_loss: 0.5611 - val_accuracy: 0.7886\n",
            "Epoch 359/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3361 - accuracy: 0.8554 - val_loss: 0.5098 - val_accuracy: 0.7967\n",
            "Epoch 360/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3152 - accuracy: 0.8697 - val_loss: 0.5348 - val_accuracy: 0.7724\n",
            "Epoch 361/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3416 - accuracy: 0.8656 - val_loss: 0.4926 - val_accuracy: 0.7886\n",
            "Epoch 362/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8513 - val_loss: 0.5106 - val_accuracy: 0.7724\n",
            "Epoch 363/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3178 - accuracy: 0.8574 - val_loss: 0.5317 - val_accuracy: 0.7805\n",
            "Epoch 364/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3254 - accuracy: 0.8615 - val_loss: 0.5098 - val_accuracy: 0.7967\n",
            "Epoch 365/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3215 - accuracy: 0.8554 - val_loss: 0.5480 - val_accuracy: 0.7886\n",
            "Epoch 366/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3209 - accuracy: 0.8574 - val_loss: 0.5674 - val_accuracy: 0.7561\n",
            "Epoch 367/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3192 - accuracy: 0.8778 - val_loss: 0.5851 - val_accuracy: 0.7886\n",
            "Epoch 368/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3108 - accuracy: 0.8900 - val_loss: 0.4983 - val_accuracy: 0.8211\n",
            "Epoch 369/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3204 - accuracy: 0.8656 - val_loss: 0.5229 - val_accuracy: 0.7805\n",
            "Epoch 370/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3121 - accuracy: 0.8534 - val_loss: 0.5798 - val_accuracy: 0.7805\n",
            "Epoch 371/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3358 - accuracy: 0.8452 - val_loss: 0.5704 - val_accuracy: 0.7724\n",
            "Epoch 372/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8534 - val_loss: 0.5440 - val_accuracy: 0.7967\n",
            "Epoch 373/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3204 - accuracy: 0.8615 - val_loss: 0.5754 - val_accuracy: 0.7642\n",
            "Epoch 374/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3329 - accuracy: 0.8391 - val_loss: 0.5591 - val_accuracy: 0.7886\n",
            "Epoch 375/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3205 - accuracy: 0.8493 - val_loss: 0.5301 - val_accuracy: 0.8049\n",
            "Epoch 376/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3005 - accuracy: 0.8697 - val_loss: 0.5779 - val_accuracy: 0.7236\n",
            "Epoch 377/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3326 - accuracy: 0.8391 - val_loss: 0.5762 - val_accuracy: 0.7561\n",
            "Epoch 378/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3298 - accuracy: 0.8432 - val_loss: 0.5466 - val_accuracy: 0.7724\n",
            "Epoch 379/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3241 - accuracy: 0.8513 - val_loss: 0.5362 - val_accuracy: 0.7886\n",
            "Epoch 380/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3336 - accuracy: 0.8635 - val_loss: 0.5510 - val_accuracy: 0.7480\n",
            "Epoch 381/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3088 - accuracy: 0.8595 - val_loss: 0.5040 - val_accuracy: 0.7967\n",
            "Epoch 382/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3173 - accuracy: 0.8554 - val_loss: 0.6113 - val_accuracy: 0.7154\n",
            "Epoch 383/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3238 - accuracy: 0.8717 - val_loss: 0.5645 - val_accuracy: 0.7886\n",
            "Epoch 384/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3104 - accuracy: 0.8615 - val_loss: 0.4931 - val_accuracy: 0.7886\n",
            "Epoch 385/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3141 - accuracy: 0.8554 - val_loss: 0.5156 - val_accuracy: 0.8049\n",
            "Epoch 386/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3067 - accuracy: 0.8615 - val_loss: 0.5602 - val_accuracy: 0.7805\n",
            "Epoch 387/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3044 - accuracy: 0.8595 - val_loss: 0.5924 - val_accuracy: 0.7724\n",
            "Epoch 388/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3050 - accuracy: 0.8615 - val_loss: 0.6138 - val_accuracy: 0.7561\n",
            "Epoch 389/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3001 - accuracy: 0.8697 - val_loss: 0.5907 - val_accuracy: 0.7561\n",
            "Epoch 390/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3076 - accuracy: 0.8697 - val_loss: 0.6069 - val_accuracy: 0.7561\n",
            "Epoch 391/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3131 - accuracy: 0.8697 - val_loss: 0.5105 - val_accuracy: 0.8049\n",
            "Epoch 392/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3109 - accuracy: 0.8473 - val_loss: 0.5067 - val_accuracy: 0.7805\n",
            "Epoch 393/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3073 - accuracy: 0.8595 - val_loss: 0.5352 - val_accuracy: 0.7561\n",
            "Epoch 394/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3124 - accuracy: 0.8697 - val_loss: 0.5237 - val_accuracy: 0.7967\n",
            "Epoch 395/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3004 - accuracy: 0.8615 - val_loss: 0.5596 - val_accuracy: 0.7398\n",
            "Epoch 396/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2988 - accuracy: 0.8717 - val_loss: 0.6004 - val_accuracy: 0.7398\n",
            "Epoch 397/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3053 - accuracy: 0.8595 - val_loss: 0.5389 - val_accuracy: 0.8374\n",
            "Epoch 398/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3076 - accuracy: 0.8656 - val_loss: 0.5827 - val_accuracy: 0.7724\n",
            "Epoch 399/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2928 - accuracy: 0.8635 - val_loss: 0.5288 - val_accuracy: 0.7805\n",
            "Epoch 400/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3158 - accuracy: 0.8554 - val_loss: 0.5174 - val_accuracy: 0.8130\n",
            "Epoch 401/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2967 - accuracy: 0.8615 - val_loss: 0.5508 - val_accuracy: 0.7724\n",
            "Epoch 402/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3137 - accuracy: 0.8697 - val_loss: 0.6125 - val_accuracy: 0.7642\n",
            "Epoch 403/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3021 - accuracy: 0.8819 - val_loss: 0.5428 - val_accuracy: 0.7642\n",
            "Epoch 404/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2983 - accuracy: 0.8758 - val_loss: 0.5809 - val_accuracy: 0.7724\n",
            "Epoch 405/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2995 - accuracy: 0.8676 - val_loss: 0.5179 - val_accuracy: 0.7724\n",
            "Epoch 406/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3110 - accuracy: 0.8758 - val_loss: 0.6228 - val_accuracy: 0.7642\n",
            "Epoch 407/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2868 - accuracy: 0.8798 - val_loss: 0.5502 - val_accuracy: 0.7886\n",
            "Epoch 408/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2775 - accuracy: 0.8798 - val_loss: 0.5838 - val_accuracy: 0.7805\n",
            "Epoch 409/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3050 - accuracy: 0.8758 - val_loss: 0.5644 - val_accuracy: 0.8049\n",
            "Epoch 410/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2951 - accuracy: 0.8697 - val_loss: 0.5585 - val_accuracy: 0.7886\n",
            "Epoch 411/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3076 - accuracy: 0.8697 - val_loss: 0.5582 - val_accuracy: 0.7886\n",
            "Epoch 412/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2876 - accuracy: 0.8758 - val_loss: 0.5518 - val_accuracy: 0.7967\n",
            "Epoch 413/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2832 - accuracy: 0.8900 - val_loss: 0.5913 - val_accuracy: 0.7480\n",
            "Epoch 414/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3150 - accuracy: 0.8595 - val_loss: 0.6078 - val_accuracy: 0.7724\n",
            "Epoch 415/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3081 - accuracy: 0.8615 - val_loss: 0.6010 - val_accuracy: 0.7805\n",
            "Epoch 416/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2907 - accuracy: 0.8778 - val_loss: 0.5602 - val_accuracy: 0.7886\n",
            "Epoch 417/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2951 - accuracy: 0.8656 - val_loss: 0.5847 - val_accuracy: 0.7805\n",
            "Epoch 418/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2937 - accuracy: 0.8656 - val_loss: 0.5604 - val_accuracy: 0.7724\n",
            "Epoch 419/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2917 - accuracy: 0.8778 - val_loss: 0.5572 - val_accuracy: 0.7967\n",
            "Epoch 420/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2854 - accuracy: 0.8778 - val_loss: 0.5753 - val_accuracy: 0.7886\n",
            "Epoch 421/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2777 - accuracy: 0.8676 - val_loss: 0.5987 - val_accuracy: 0.7886\n",
            "Epoch 422/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3050 - accuracy: 0.8656 - val_loss: 0.6082 - val_accuracy: 0.7561\n",
            "Epoch 423/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2838 - accuracy: 0.8859 - val_loss: 0.5868 - val_accuracy: 0.7724\n",
            "Epoch 424/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2972 - accuracy: 0.8676 - val_loss: 0.5130 - val_accuracy: 0.8211\n",
            "Epoch 425/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2872 - accuracy: 0.8513 - val_loss: 0.5675 - val_accuracy: 0.7886\n",
            "Epoch 426/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2858 - accuracy: 0.8717 - val_loss: 0.6311 - val_accuracy: 0.7724\n",
            "Epoch 427/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2794 - accuracy: 0.8819 - val_loss: 0.5784 - val_accuracy: 0.8130\n",
            "Epoch 428/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2769 - accuracy: 0.8839 - val_loss: 0.7253 - val_accuracy: 0.7642\n",
            "Epoch 429/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2803 - accuracy: 0.8819 - val_loss: 0.5731 - val_accuracy: 0.7805\n",
            "Epoch 430/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2662 - accuracy: 0.8839 - val_loss: 0.5474 - val_accuracy: 0.8049\n",
            "Epoch 431/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3509 - accuracy: 0.8391 - val_loss: 0.6202 - val_accuracy: 0.7480\n",
            "Epoch 432/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2914 - accuracy: 0.8778 - val_loss: 0.5467 - val_accuracy: 0.8049\n",
            "Epoch 433/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2770 - accuracy: 0.8798 - val_loss: 0.6021 - val_accuracy: 0.7724\n",
            "Epoch 434/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2667 - accuracy: 0.8778 - val_loss: 0.7015 - val_accuracy: 0.6829\n",
            "Epoch 435/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2895 - accuracy: 0.8717 - val_loss: 0.6485 - val_accuracy: 0.7480\n",
            "Epoch 436/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3000 - accuracy: 0.8697 - val_loss: 0.5919 - val_accuracy: 0.7724\n",
            "Epoch 437/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2638 - accuracy: 0.8880 - val_loss: 0.5316 - val_accuracy: 0.8130\n",
            "Epoch 438/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2775 - accuracy: 0.8798 - val_loss: 0.5677 - val_accuracy: 0.8049\n",
            "Epoch 439/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2629 - accuracy: 0.8941 - val_loss: 0.6068 - val_accuracy: 0.7642\n",
            "Epoch 440/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2853 - accuracy: 0.8737 - val_loss: 0.7153 - val_accuracy: 0.7642\n",
            "Epoch 441/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2796 - accuracy: 0.8778 - val_loss: 0.6202 - val_accuracy: 0.7561\n",
            "Epoch 442/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2762 - accuracy: 0.8880 - val_loss: 0.6437 - val_accuracy: 0.7805\n",
            "Epoch 443/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2940 - accuracy: 0.8758 - val_loss: 0.6169 - val_accuracy: 0.7886\n",
            "Epoch 444/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2868 - accuracy: 0.8737 - val_loss: 0.6174 - val_accuracy: 0.7886\n",
            "Epoch 445/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2581 - accuracy: 0.8880 - val_loss: 0.5724 - val_accuracy: 0.7724\n",
            "Epoch 446/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2688 - accuracy: 0.8880 - val_loss: 0.7205 - val_accuracy: 0.7236\n",
            "Epoch 447/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3259 - accuracy: 0.8574 - val_loss: 0.6046 - val_accuracy: 0.7642\n",
            "Epoch 448/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2872 - accuracy: 0.8798 - val_loss: 0.6603 - val_accuracy: 0.7561\n",
            "Epoch 449/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2781 - accuracy: 0.8819 - val_loss: 0.6713 - val_accuracy: 0.7724\n",
            "Epoch 450/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2945 - accuracy: 0.8697 - val_loss: 0.5966 - val_accuracy: 0.7805\n",
            "Epoch 451/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2878 - accuracy: 0.8676 - val_loss: 0.6433 - val_accuracy: 0.7724\n",
            "Epoch 452/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2759 - accuracy: 0.8839 - val_loss: 0.5955 - val_accuracy: 0.6992\n",
            "Epoch 453/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3002 - accuracy: 0.8737 - val_loss: 0.6008 - val_accuracy: 0.7724\n",
            "Epoch 454/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2559 - accuracy: 0.8839 - val_loss: 0.6423 - val_accuracy: 0.7480\n",
            "Epoch 455/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2540 - accuracy: 0.8941 - val_loss: 0.6124 - val_accuracy: 0.7642\n",
            "Epoch 456/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2722 - accuracy: 0.8737 - val_loss: 0.7249 - val_accuracy: 0.6992\n",
            "Epoch 457/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2645 - accuracy: 0.8941 - val_loss: 0.5598 - val_accuracy: 0.7805\n",
            "Epoch 458/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2738 - accuracy: 0.8859 - val_loss: 0.5579 - val_accuracy: 0.8130\n",
            "Epoch 459/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2606 - accuracy: 0.8880 - val_loss: 0.6193 - val_accuracy: 0.7967\n",
            "Epoch 460/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2581 - accuracy: 0.8819 - val_loss: 0.6573 - val_accuracy: 0.7398\n",
            "Epoch 461/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2792 - accuracy: 0.8839 - val_loss: 0.5817 - val_accuracy: 0.7886\n",
            "Epoch 462/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2854 - accuracy: 0.8778 - val_loss: 0.5448 - val_accuracy: 0.8049\n",
            "Epoch 463/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2750 - accuracy: 0.8798 - val_loss: 0.5995 - val_accuracy: 0.7480\n",
            "Epoch 464/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2654 - accuracy: 0.8798 - val_loss: 0.6302 - val_accuracy: 0.7886\n",
            "Epoch 465/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2586 - accuracy: 0.8798 - val_loss: 0.7283 - val_accuracy: 0.7480\n",
            "Epoch 466/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2656 - accuracy: 0.8819 - val_loss: 0.7065 - val_accuracy: 0.7805\n",
            "Epoch 467/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2785 - accuracy: 0.8819 - val_loss: 0.7076 - val_accuracy: 0.7724\n",
            "Epoch 468/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2624 - accuracy: 0.9022 - val_loss: 0.6022 - val_accuracy: 0.8049\n",
            "Epoch 469/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2789 - accuracy: 0.8859 - val_loss: 0.6091 - val_accuracy: 0.7561\n",
            "Epoch 470/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2604 - accuracy: 0.9022 - val_loss: 0.6470 - val_accuracy: 0.7805\n",
            "Epoch 471/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2539 - accuracy: 0.8819 - val_loss: 0.6052 - val_accuracy: 0.7805\n",
            "Epoch 472/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2627 - accuracy: 0.8615 - val_loss: 0.6551 - val_accuracy: 0.7805\n",
            "Epoch 473/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2728 - accuracy: 0.8859 - val_loss: 0.6028 - val_accuracy: 0.7642\n",
            "Epoch 474/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2706 - accuracy: 0.8839 - val_loss: 0.6432 - val_accuracy: 0.7561\n",
            "Epoch 475/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2577 - accuracy: 0.9002 - val_loss: 0.5858 - val_accuracy: 0.8130\n",
            "Epoch 476/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2457 - accuracy: 0.9043 - val_loss: 0.6125 - val_accuracy: 0.7886\n",
            "Epoch 477/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2569 - accuracy: 0.8880 - val_loss: 0.6498 - val_accuracy: 0.7480\n",
            "Epoch 478/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2423 - accuracy: 0.9022 - val_loss: 0.7014 - val_accuracy: 0.7480\n",
            "Epoch 479/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2849 - accuracy: 0.8635 - val_loss: 0.5973 - val_accuracy: 0.8049\n",
            "Epoch 480/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2406 - accuracy: 0.8982 - val_loss: 0.6048 - val_accuracy: 0.7805\n",
            "Epoch 481/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2342 - accuracy: 0.8961 - val_loss: 0.6053 - val_accuracy: 0.7805\n",
            "Epoch 482/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2635 - accuracy: 0.8941 - val_loss: 0.5743 - val_accuracy: 0.7967\n",
            "Epoch 483/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2416 - accuracy: 0.9043 - val_loss: 0.6353 - val_accuracy: 0.7886\n",
            "Epoch 484/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2597 - accuracy: 0.8819 - val_loss: 0.6139 - val_accuracy: 0.7805\n",
            "Epoch 485/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2958 - accuracy: 0.8635 - val_loss: 0.6251 - val_accuracy: 0.7967\n",
            "Epoch 486/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2548 - accuracy: 0.8859 - val_loss: 0.5964 - val_accuracy: 0.7724\n",
            "Epoch 487/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.8961 - val_loss: 0.6115 - val_accuracy: 0.7886\n",
            "Epoch 488/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2460 - accuracy: 0.8941 - val_loss: 0.7058 - val_accuracy: 0.7724\n",
            "Epoch 489/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2211 - accuracy: 0.9145 - val_loss: 0.6506 - val_accuracy: 0.8211\n",
            "Epoch 490/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2571 - accuracy: 0.8900 - val_loss: 0.6660 - val_accuracy: 0.7480\n",
            "Epoch 491/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2473 - accuracy: 0.9002 - val_loss: 0.6759 - val_accuracy: 0.7805\n",
            "Epoch 492/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2466 - accuracy: 0.9022 - val_loss: 0.6253 - val_accuracy: 0.7886\n",
            "Epoch 493/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2357 - accuracy: 0.8982 - val_loss: 0.6986 - val_accuracy: 0.7317\n",
            "Epoch 494/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2516 - accuracy: 0.8839 - val_loss: 0.6061 - val_accuracy: 0.7724\n",
            "Epoch 495/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2619 - accuracy: 0.8798 - val_loss: 0.6934 - val_accuracy: 0.6911\n",
            "Epoch 496/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2313 - accuracy: 0.9002 - val_loss: 0.6304 - val_accuracy: 0.7642\n",
            "Epoch 497/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2453 - accuracy: 0.8819 - val_loss: 0.6690 - val_accuracy: 0.7967\n",
            "Epoch 498/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2365 - accuracy: 0.9022 - val_loss: 0.6534 - val_accuracy: 0.7398\n",
            "Epoch 499/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2634 - accuracy: 0.8961 - val_loss: 0.6084 - val_accuracy: 0.7967\n",
            "Epoch 500/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2331 - accuracy: 0.9022 - val_loss: 0.6817 - val_accuracy: 0.7724\n",
            "Epoch 501/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2401 - accuracy: 0.8839 - val_loss: 0.6688 - val_accuracy: 0.7886\n",
            "Epoch 502/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2535 - accuracy: 0.9063 - val_loss: 0.6305 - val_accuracy: 0.7886\n",
            "Epoch 503/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2457 - accuracy: 0.8798 - val_loss: 0.6731 - val_accuracy: 0.7886\n",
            "Epoch 504/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.3009 - accuracy: 0.8717 - val_loss: 0.5991 - val_accuracy: 0.7642\n",
            "Epoch 505/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2480 - accuracy: 0.8982 - val_loss: 0.6268 - val_accuracy: 0.8049\n",
            "Epoch 506/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2379 - accuracy: 0.9022 - val_loss: 0.6916 - val_accuracy: 0.7642\n",
            "Epoch 507/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2598 - accuracy: 0.8921 - val_loss: 0.5588 - val_accuracy: 0.8211\n",
            "Epoch 508/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3170 - accuracy: 0.8737 - val_loss: 0.6557 - val_accuracy: 0.7398\n",
            "Epoch 509/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2206 - accuracy: 0.9084 - val_loss: 0.6339 - val_accuracy: 0.7805\n",
            "Epoch 510/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2502 - accuracy: 0.8941 - val_loss: 0.6778 - val_accuracy: 0.7724\n",
            "Epoch 511/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2276 - accuracy: 0.9043 - val_loss: 0.7998 - val_accuracy: 0.7317\n",
            "Epoch 512/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2379 - accuracy: 0.9084 - val_loss: 0.5993 - val_accuracy: 0.7805\n",
            "Epoch 513/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2444 - accuracy: 0.8921 - val_loss: 0.6575 - val_accuracy: 0.7886\n",
            "Epoch 514/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2295 - accuracy: 0.9084 - val_loss: 0.5951 - val_accuracy: 0.7886\n",
            "Epoch 515/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2749 - accuracy: 0.8839 - val_loss: 0.6400 - val_accuracy: 0.8049\n",
            "Epoch 516/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2160 - accuracy: 0.9063 - val_loss: 0.6272 - val_accuracy: 0.7398\n",
            "Epoch 517/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2473 - accuracy: 0.8900 - val_loss: 0.6148 - val_accuracy: 0.7886\n",
            "Epoch 518/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2307 - accuracy: 0.9084 - val_loss: 0.6248 - val_accuracy: 0.7967\n",
            "Epoch 519/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2487 - accuracy: 0.8982 - val_loss: 0.5975 - val_accuracy: 0.7967\n",
            "Epoch 520/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2291 - accuracy: 0.9084 - val_loss: 0.7230 - val_accuracy: 0.7561\n",
            "Epoch 521/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2220 - accuracy: 0.9043 - val_loss: 0.6333 - val_accuracy: 0.7805\n",
            "Epoch 522/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2214 - accuracy: 0.9002 - val_loss: 0.6886 - val_accuracy: 0.7642\n",
            "Epoch 523/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2548 - accuracy: 0.8880 - val_loss: 0.6810 - val_accuracy: 0.7967\n",
            "Epoch 524/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2185 - accuracy: 0.8900 - val_loss: 0.7249 - val_accuracy: 0.7642\n",
            "Epoch 525/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2422 - accuracy: 0.8900 - val_loss: 0.6687 - val_accuracy: 0.7886\n",
            "Epoch 526/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2405 - accuracy: 0.8961 - val_loss: 0.7431 - val_accuracy: 0.7480\n",
            "Epoch 527/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2226 - accuracy: 0.9002 - val_loss: 0.6803 - val_accuracy: 0.7967\n",
            "Epoch 528/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2318 - accuracy: 0.8961 - val_loss: 0.6114 - val_accuracy: 0.7967\n",
            "Epoch 529/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2042 - accuracy: 0.9226 - val_loss: 0.6536 - val_accuracy: 0.7805\n",
            "Epoch 530/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2181 - accuracy: 0.9104 - val_loss: 0.5948 - val_accuracy: 0.7805\n",
            "Epoch 531/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2314 - accuracy: 0.8900 - val_loss: 0.6543 - val_accuracy: 0.7886\n",
            "Epoch 532/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2252 - accuracy: 0.9043 - val_loss: 0.6532 - val_accuracy: 0.7805\n",
            "Epoch 533/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2083 - accuracy: 0.9165 - val_loss: 0.7587 - val_accuracy: 0.7967\n",
            "Epoch 534/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1954 - accuracy: 0.9246 - val_loss: 0.6819 - val_accuracy: 0.7724\n",
            "Epoch 535/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2322 - accuracy: 0.9063 - val_loss: 0.7421 - val_accuracy: 0.7561\n",
            "Epoch 536/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2023 - accuracy: 0.9145 - val_loss: 0.6653 - val_accuracy: 0.7642\n",
            "Epoch 537/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2593 - accuracy: 0.8921 - val_loss: 0.6270 - val_accuracy: 0.7642\n",
            "Epoch 538/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2292 - accuracy: 0.8921 - val_loss: 0.6766 - val_accuracy: 0.7561\n",
            "Epoch 539/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2121 - accuracy: 0.9022 - val_loss: 0.6781 - val_accuracy: 0.7480\n",
            "Epoch 540/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2245 - accuracy: 0.9084 - val_loss: 0.6256 - val_accuracy: 0.7724\n",
            "Epoch 541/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2227 - accuracy: 0.9002 - val_loss: 0.8226 - val_accuracy: 0.7236\n",
            "Epoch 542/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2351 - accuracy: 0.9124 - val_loss: 0.6706 - val_accuracy: 0.7480\n",
            "Epoch 543/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2355 - accuracy: 0.9063 - val_loss: 0.6907 - val_accuracy: 0.7561\n",
            "Epoch 544/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2584 - accuracy: 0.8839 - val_loss: 0.5949 - val_accuracy: 0.7967\n",
            "Epoch 545/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2246 - accuracy: 0.9043 - val_loss: 0.6259 - val_accuracy: 0.8374\n",
            "Epoch 546/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2024 - accuracy: 0.9104 - val_loss: 0.6483 - val_accuracy: 0.7398\n",
            "Epoch 547/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2211 - accuracy: 0.9104 - val_loss: 0.6698 - val_accuracy: 0.8049\n",
            "Epoch 548/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2442 - accuracy: 0.8900 - val_loss: 0.6456 - val_accuracy: 0.7886\n",
            "Epoch 549/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2339 - accuracy: 0.9022 - val_loss: 0.6483 - val_accuracy: 0.7642\n",
            "Epoch 550/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2293 - accuracy: 0.9165 - val_loss: 0.7087 - val_accuracy: 0.7805\n",
            "Epoch 551/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2235 - accuracy: 0.9002 - val_loss: 0.7395 - val_accuracy: 0.7642\n",
            "Epoch 552/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2090 - accuracy: 0.9063 - val_loss: 0.6326 - val_accuracy: 0.7967\n",
            "Epoch 553/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2100 - accuracy: 0.9145 - val_loss: 0.6788 - val_accuracy: 0.8049\n",
            "Epoch 554/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2086 - accuracy: 0.8982 - val_loss: 0.6587 - val_accuracy: 0.7805\n",
            "Epoch 555/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2336 - accuracy: 0.8982 - val_loss: 0.6865 - val_accuracy: 0.7724\n",
            "Epoch 556/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.8900 - val_loss: 0.6196 - val_accuracy: 0.7805\n",
            "Epoch 557/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2103 - accuracy: 0.9084 - val_loss: 0.6474 - val_accuracy: 0.7724\n",
            "Epoch 558/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1969 - accuracy: 0.9226 - val_loss: 0.6828 - val_accuracy: 0.7561\n",
            "Epoch 559/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2138 - accuracy: 0.9104 - val_loss: 0.6425 - val_accuracy: 0.7886\n",
            "Epoch 560/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2286 - accuracy: 0.8961 - val_loss: 0.6387 - val_accuracy: 0.8049\n",
            "Epoch 561/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2036 - accuracy: 0.9185 - val_loss: 0.7193 - val_accuracy: 0.7967\n",
            "Epoch 562/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1987 - accuracy: 0.9246 - val_loss: 0.6782 - val_accuracy: 0.7724\n",
            "Epoch 563/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1931 - accuracy: 0.9084 - val_loss: 0.6051 - val_accuracy: 0.8130\n",
            "Epoch 564/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2287 - accuracy: 0.9022 - val_loss: 0.7390 - val_accuracy: 0.7317\n",
            "Epoch 565/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2204 - accuracy: 0.9022 - val_loss: 0.7156 - val_accuracy: 0.7886\n",
            "Epoch 566/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2135 - accuracy: 0.9084 - val_loss: 0.8008 - val_accuracy: 0.7154\n",
            "Epoch 567/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2151 - accuracy: 0.9104 - val_loss: 0.7344 - val_accuracy: 0.7805\n",
            "Epoch 568/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1976 - accuracy: 0.9084 - val_loss: 0.7499 - val_accuracy: 0.7805\n",
            "Epoch 569/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2154 - accuracy: 0.9002 - val_loss: 0.6994 - val_accuracy: 0.7480\n",
            "Epoch 570/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1954 - accuracy: 0.9206 - val_loss: 0.7293 - val_accuracy: 0.7967\n",
            "Epoch 571/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2224 - accuracy: 0.9124 - val_loss: 0.7141 - val_accuracy: 0.7724\n",
            "Epoch 572/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1890 - accuracy: 0.9287 - val_loss: 0.8044 - val_accuracy: 0.7967\n",
            "Epoch 573/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2178 - accuracy: 0.9104 - val_loss: 0.6999 - val_accuracy: 0.7724\n",
            "Epoch 574/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2100 - accuracy: 0.8982 - val_loss: 0.6677 - val_accuracy: 0.7886\n",
            "Epoch 575/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1754 - accuracy: 0.9389 - val_loss: 0.6711 - val_accuracy: 0.7967\n",
            "Epoch 576/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2195 - accuracy: 0.9022 - val_loss: 0.7294 - val_accuracy: 0.7236\n",
            "Epoch 577/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2517 - accuracy: 0.9043 - val_loss: 0.7835 - val_accuracy: 0.7073\n",
            "Epoch 578/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2036 - accuracy: 0.9124 - val_loss: 0.7380 - val_accuracy: 0.7886\n",
            "Epoch 579/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1826 - accuracy: 0.9267 - val_loss: 0.6582 - val_accuracy: 0.7724\n",
            "Epoch 580/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1862 - accuracy: 0.9226 - val_loss: 0.6850 - val_accuracy: 0.7886\n",
            "Epoch 581/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2023 - accuracy: 0.9185 - val_loss: 0.8403 - val_accuracy: 0.6911\n",
            "Epoch 582/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2354 - accuracy: 0.9002 - val_loss: 0.8297 - val_accuracy: 0.7073\n",
            "Epoch 583/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2457 - accuracy: 0.8839 - val_loss: 0.6772 - val_accuracy: 0.7805\n",
            "Epoch 584/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2037 - accuracy: 0.9124 - val_loss: 0.6825 - val_accuracy: 0.7886\n",
            "Epoch 585/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2092 - accuracy: 0.9226 - val_loss: 0.7045 - val_accuracy: 0.7480\n",
            "Epoch 586/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1873 - accuracy: 0.9328 - val_loss: 0.7100 - val_accuracy: 0.7642\n",
            "Epoch 587/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2199 - accuracy: 0.9104 - val_loss: 0.7149 - val_accuracy: 0.7642\n",
            "Epoch 588/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2132 - accuracy: 0.9104 - val_loss: 0.7134 - val_accuracy: 0.7317\n",
            "Epoch 589/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2210 - accuracy: 0.9043 - val_loss: 0.7411 - val_accuracy: 0.7805\n",
            "Epoch 590/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2091 - accuracy: 0.9124 - val_loss: 0.6845 - val_accuracy: 0.7642\n",
            "Epoch 591/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1922 - accuracy: 0.9267 - val_loss: 0.7366 - val_accuracy: 0.7724\n",
            "Epoch 592/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1819 - accuracy: 0.9226 - val_loss: 0.7704 - val_accuracy: 0.7886\n",
            "Epoch 593/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1956 - accuracy: 0.9145 - val_loss: 0.7965 - val_accuracy: 0.7724\n",
            "Epoch 594/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2511 - accuracy: 0.8982 - val_loss: 0.6626 - val_accuracy: 0.7886\n",
            "Epoch 595/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1856 - accuracy: 0.9226 - val_loss: 0.8115 - val_accuracy: 0.7805\n",
            "Epoch 596/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1958 - accuracy: 0.9267 - val_loss: 0.7575 - val_accuracy: 0.7561\n",
            "Epoch 597/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1792 - accuracy: 0.9185 - val_loss: 0.8152 - val_accuracy: 0.7398\n",
            "Epoch 598/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1938 - accuracy: 0.9063 - val_loss: 0.7574 - val_accuracy: 0.7886\n",
            "Epoch 599/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1971 - accuracy: 0.9104 - val_loss: 0.7025 - val_accuracy: 0.8049\n",
            "Epoch 600/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1795 - accuracy: 0.9246 - val_loss: 0.7145 - val_accuracy: 0.7886\n",
            "Epoch 601/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1690 - accuracy: 0.9389 - val_loss: 0.9941 - val_accuracy: 0.7642\n",
            "Epoch 602/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2362 - accuracy: 0.8961 - val_loss: 0.8716 - val_accuracy: 0.7561\n",
            "Epoch 603/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1862 - accuracy: 0.9226 - val_loss: 0.7083 - val_accuracy: 0.7805\n",
            "Epoch 604/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1720 - accuracy: 0.9308 - val_loss: 0.7974 - val_accuracy: 0.7805\n",
            "Epoch 605/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2030 - accuracy: 0.9226 - val_loss: 0.7668 - val_accuracy: 0.7886\n",
            "Epoch 606/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1894 - accuracy: 0.9165 - val_loss: 0.7621 - val_accuracy: 0.7805\n",
            "Epoch 607/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2098 - accuracy: 0.9206 - val_loss: 0.7900 - val_accuracy: 0.7317\n",
            "Epoch 608/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1846 - accuracy: 0.9165 - val_loss: 0.7760 - val_accuracy: 0.7642\n",
            "Epoch 609/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1881 - accuracy: 0.9246 - val_loss: 0.7224 - val_accuracy: 0.7724\n",
            "Epoch 610/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1662 - accuracy: 0.9246 - val_loss: 0.7663 - val_accuracy: 0.7805\n",
            "Epoch 611/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2327 - accuracy: 0.8900 - val_loss: 0.7409 - val_accuracy: 0.7317\n",
            "Epoch 612/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1892 - accuracy: 0.9124 - val_loss: 0.7541 - val_accuracy: 0.7805\n",
            "Epoch 613/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2063 - accuracy: 0.9043 - val_loss: 0.9147 - val_accuracy: 0.7724\n",
            "Epoch 614/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1961 - accuracy: 0.9104 - val_loss: 0.7244 - val_accuracy: 0.7480\n",
            "Epoch 615/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1703 - accuracy: 0.9287 - val_loss: 0.8866 - val_accuracy: 0.7154\n",
            "Epoch 616/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1932 - accuracy: 0.9124 - val_loss: 0.8167 - val_accuracy: 0.7398\n",
            "Epoch 617/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2085 - accuracy: 0.9124 - val_loss: 0.7580 - val_accuracy: 0.7724\n",
            "Epoch 618/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1772 - accuracy: 0.9328 - val_loss: 0.7541 - val_accuracy: 0.7642\n",
            "Epoch 619/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1769 - accuracy: 0.9287 - val_loss: 0.7993 - val_accuracy: 0.7724\n",
            "Epoch 620/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1764 - accuracy: 0.9246 - val_loss: 0.7143 - val_accuracy: 0.7642\n",
            "Epoch 621/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1564 - accuracy: 0.9348 - val_loss: 0.7821 - val_accuracy: 0.7724\n",
            "Epoch 622/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2154 - accuracy: 0.9043 - val_loss: 0.8394 - val_accuracy: 0.7480\n",
            "Epoch 623/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1638 - accuracy: 0.9267 - val_loss: 0.7726 - val_accuracy: 0.7561\n",
            "Epoch 624/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1748 - accuracy: 0.9308 - val_loss: 0.8218 - val_accuracy: 0.7886\n",
            "Epoch 625/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2022 - accuracy: 0.9124 - val_loss: 0.7840 - val_accuracy: 0.7480\n",
            "Epoch 626/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1702 - accuracy: 0.9226 - val_loss: 0.8747 - val_accuracy: 0.7724\n",
            "Epoch 627/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1569 - accuracy: 0.9389 - val_loss: 0.8327 - val_accuracy: 0.7642\n",
            "Epoch 628/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1630 - accuracy: 0.9308 - val_loss: 0.8298 - val_accuracy: 0.8049\n",
            "Epoch 629/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1691 - accuracy: 0.9287 - val_loss: 0.7974 - val_accuracy: 0.7480\n",
            "Epoch 630/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1880 - accuracy: 0.9063 - val_loss: 0.8483 - val_accuracy: 0.7642\n",
            "Epoch 631/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1666 - accuracy: 0.9287 - val_loss: 0.8014 - val_accuracy: 0.8049\n",
            "Epoch 632/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1851 - accuracy: 0.9226 - val_loss: 0.7734 - val_accuracy: 0.7642\n",
            "Epoch 633/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1992 - accuracy: 0.9084 - val_loss: 0.8342 - val_accuracy: 0.7561\n",
            "Epoch 634/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1642 - accuracy: 0.9267 - val_loss: 0.7283 - val_accuracy: 0.7724\n",
            "Epoch 635/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1696 - accuracy: 0.9308 - val_loss: 0.8022 - val_accuracy: 0.7805\n",
            "Epoch 636/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1830 - accuracy: 0.9145 - val_loss: 0.8259 - val_accuracy: 0.7642\n",
            "Epoch 637/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1991 - accuracy: 0.9145 - val_loss: 0.8239 - val_accuracy: 0.7236\n",
            "Epoch 638/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1745 - accuracy: 0.9308 - val_loss: 0.8455 - val_accuracy: 0.7561\n",
            "Epoch 639/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1671 - accuracy: 0.9287 - val_loss: 0.8546 - val_accuracy: 0.7642\n",
            "Epoch 640/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2283 - accuracy: 0.9043 - val_loss: 0.8419 - val_accuracy: 0.7236\n",
            "Epoch 641/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1889 - accuracy: 0.9165 - val_loss: 0.8103 - val_accuracy: 0.7886\n",
            "Epoch 642/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1863 - accuracy: 0.9267 - val_loss: 0.7289 - val_accuracy: 0.7480\n",
            "Epoch 643/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1737 - accuracy: 0.9246 - val_loss: 0.7371 - val_accuracy: 0.7561\n",
            "Epoch 644/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1594 - accuracy: 0.9328 - val_loss: 0.7963 - val_accuracy: 0.7398\n",
            "Epoch 645/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2275 - accuracy: 0.8961 - val_loss: 0.8951 - val_accuracy: 0.7480\n",
            "Epoch 646/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1486 - accuracy: 0.9287 - val_loss: 0.8233 - val_accuracy: 0.7561\n",
            "Epoch 647/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1800 - accuracy: 0.9328 - val_loss: 0.9477 - val_accuracy: 0.7561\n",
            "Epoch 648/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2564 - accuracy: 0.9002 - val_loss: 0.8041 - val_accuracy: 0.7561\n",
            "Epoch 649/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1653 - accuracy: 0.9348 - val_loss: 0.7277 - val_accuracy: 0.7886\n",
            "Epoch 650/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1727 - accuracy: 0.9226 - val_loss: 0.7568 - val_accuracy: 0.7805\n",
            "Epoch 651/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2094 - accuracy: 0.9165 - val_loss: 0.8185 - val_accuracy: 0.7642\n",
            "Epoch 652/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1859 - accuracy: 0.9084 - val_loss: 0.7575 - val_accuracy: 0.7886\n",
            "Epoch 653/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1520 - accuracy: 0.9348 - val_loss: 0.8164 - val_accuracy: 0.7398\n",
            "Epoch 654/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1490 - accuracy: 0.9389 - val_loss: 0.8322 - val_accuracy: 0.7642\n",
            "Epoch 655/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1447 - accuracy: 0.9511 - val_loss: 0.9027 - val_accuracy: 0.7724\n",
            "Epoch 656/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1661 - accuracy: 0.9308 - val_loss: 0.8314 - val_accuracy: 0.7724\n",
            "Epoch 657/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1860 - accuracy: 0.9206 - val_loss: 0.9337 - val_accuracy: 0.7398\n",
            "Epoch 658/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1812 - accuracy: 0.9267 - val_loss: 0.9046 - val_accuracy: 0.7805\n",
            "Epoch 659/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1658 - accuracy: 0.9328 - val_loss: 0.8560 - val_accuracy: 0.7236\n",
            "Epoch 660/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1675 - accuracy: 0.9165 - val_loss: 0.8966 - val_accuracy: 0.7480\n",
            "Epoch 661/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1601 - accuracy: 0.9369 - val_loss: 0.8081 - val_accuracy: 0.7724\n",
            "Epoch 662/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1979 - accuracy: 0.9246 - val_loss: 0.9011 - val_accuracy: 0.7886\n",
            "Epoch 663/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1831 - accuracy: 0.9308 - val_loss: 0.8875 - val_accuracy: 0.7724\n",
            "Epoch 664/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2018 - accuracy: 0.9145 - val_loss: 0.9341 - val_accuracy: 0.7480\n",
            "Epoch 665/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2147 - accuracy: 0.9124 - val_loss: 0.8363 - val_accuracy: 0.7642\n",
            "Epoch 666/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1508 - accuracy: 0.9369 - val_loss: 0.7599 - val_accuracy: 0.7724\n",
            "Epoch 667/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1649 - accuracy: 0.9246 - val_loss: 0.8141 - val_accuracy: 0.7398\n",
            "Epoch 668/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1555 - accuracy: 0.9389 - val_loss: 0.8277 - val_accuracy: 0.7236\n",
            "Epoch 669/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1653 - accuracy: 0.9287 - val_loss: 0.8754 - val_accuracy: 0.7154\n",
            "Epoch 670/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2791 - accuracy: 0.8941 - val_loss: 0.7837 - val_accuracy: 0.7642\n",
            "Epoch 671/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1668 - accuracy: 0.9165 - val_loss: 0.8366 - val_accuracy: 0.8049\n",
            "Epoch 672/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1637 - accuracy: 0.9308 - val_loss: 0.8774 - val_accuracy: 0.7805\n",
            "Epoch 673/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1637 - accuracy: 0.9328 - val_loss: 0.8617 - val_accuracy: 0.7642\n",
            "Epoch 674/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1495 - accuracy: 0.9430 - val_loss: 0.8963 - val_accuracy: 0.7398\n",
            "Epoch 675/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1573 - accuracy: 0.9308 - val_loss: 0.8888 - val_accuracy: 0.7561\n",
            "Epoch 676/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1992 - accuracy: 0.9226 - val_loss: 0.9304 - val_accuracy: 0.7317\n",
            "Epoch 677/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2923 - accuracy: 0.8676 - val_loss: 0.7464 - val_accuracy: 0.7317\n",
            "Epoch 678/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1415 - accuracy: 0.9552 - val_loss: 0.7787 - val_accuracy: 0.7805\n",
            "Epoch 679/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1361 - accuracy: 0.9511 - val_loss: 0.8652 - val_accuracy: 0.7642\n",
            "Epoch 680/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1302 - accuracy: 0.9552 - val_loss: 0.9022 - val_accuracy: 0.7886\n",
            "Epoch 681/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1480 - accuracy: 0.9389 - val_loss: 0.7963 - val_accuracy: 0.7398\n",
            "Epoch 682/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2626 - accuracy: 0.8982 - val_loss: 0.8909 - val_accuracy: 0.7886\n",
            "Epoch 683/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1298 - accuracy: 0.9450 - val_loss: 0.8157 - val_accuracy: 0.7642\n",
            "Epoch 684/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1530 - accuracy: 0.9491 - val_loss: 0.8145 - val_accuracy: 0.7561\n",
            "Epoch 685/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1392 - accuracy: 0.9409 - val_loss: 0.9948 - val_accuracy: 0.7642\n",
            "Epoch 686/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1227 - accuracy: 0.9450 - val_loss: 0.8391 - val_accuracy: 0.7886\n",
            "Epoch 687/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1549 - accuracy: 0.9389 - val_loss: 0.8904 - val_accuracy: 0.7805\n",
            "Epoch 688/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2087 - accuracy: 0.9226 - val_loss: 0.9044 - val_accuracy: 0.7561\n",
            "Epoch 689/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2359 - accuracy: 0.9022 - val_loss: 0.8952 - val_accuracy: 0.7561\n",
            "Epoch 690/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1321 - accuracy: 0.9532 - val_loss: 0.9334 - val_accuracy: 0.7886\n",
            "Epoch 691/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1584 - accuracy: 0.9389 - val_loss: 0.8634 - val_accuracy: 0.7480\n",
            "Epoch 692/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1355 - accuracy: 0.9328 - val_loss: 0.8997 - val_accuracy: 0.7805\n",
            "Epoch 693/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1606 - accuracy: 0.9348 - val_loss: 0.8623 - val_accuracy: 0.7480\n",
            "Epoch 694/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1468 - accuracy: 0.9409 - val_loss: 0.8920 - val_accuracy: 0.7724\n",
            "Epoch 695/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2197 - accuracy: 0.9185 - val_loss: 0.8236 - val_accuracy: 0.7642\n",
            "Epoch 696/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1514 - accuracy: 0.9470 - val_loss: 0.8748 - val_accuracy: 0.7724\n",
            "Epoch 697/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1837 - accuracy: 0.9267 - val_loss: 0.9001 - val_accuracy: 0.7480\n",
            "Epoch 698/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1603 - accuracy: 0.9409 - val_loss: 0.8044 - val_accuracy: 0.7967\n",
            "Epoch 699/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2040 - accuracy: 0.9104 - val_loss: 0.9551 - val_accuracy: 0.7805\n",
            "Epoch 700/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1970 - accuracy: 0.9328 - val_loss: 0.7776 - val_accuracy: 0.7886\n",
            "Epoch 701/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1611 - accuracy: 0.9450 - val_loss: 0.9438 - val_accuracy: 0.7886\n",
            "Epoch 702/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1496 - accuracy: 0.9430 - val_loss: 0.8648 - val_accuracy: 0.7317\n",
            "Epoch 703/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1925 - accuracy: 0.9104 - val_loss: 0.8770 - val_accuracy: 0.7480\n",
            "Epoch 704/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1464 - accuracy: 0.9450 - val_loss: 0.8871 - val_accuracy: 0.7805\n",
            "Epoch 705/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1351 - accuracy: 0.9470 - val_loss: 0.8615 - val_accuracy: 0.7561\n",
            "Epoch 706/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1545 - accuracy: 0.9430 - val_loss: 0.9090 - val_accuracy: 0.7317\n",
            "Epoch 707/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1617 - accuracy: 0.9308 - val_loss: 0.9528 - val_accuracy: 0.7642\n",
            "Epoch 708/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1285 - accuracy: 0.9450 - val_loss: 1.0796 - val_accuracy: 0.7561\n",
            "Epoch 709/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1402 - accuracy: 0.9532 - val_loss: 0.9456 - val_accuracy: 0.7561\n",
            "Epoch 710/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1460 - accuracy: 0.9470 - val_loss: 0.8914 - val_accuracy: 0.7398\n",
            "Epoch 711/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1482 - accuracy: 0.9328 - val_loss: 0.8823 - val_accuracy: 0.8049\n",
            "Epoch 712/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1418 - accuracy: 0.9511 - val_loss: 0.8475 - val_accuracy: 0.7480\n",
            "Epoch 713/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1254 - accuracy: 0.9491 - val_loss: 0.8932 - val_accuracy: 0.7561\n",
            "Epoch 714/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1423 - accuracy: 0.9470 - val_loss: 0.9731 - val_accuracy: 0.7480\n",
            "Epoch 715/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2244 - accuracy: 0.9063 - val_loss: 0.9618 - val_accuracy: 0.7398\n",
            "Epoch 716/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2845 - accuracy: 0.8982 - val_loss: 0.8875 - val_accuracy: 0.7724\n",
            "Epoch 717/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1430 - accuracy: 0.9409 - val_loss: 1.0816 - val_accuracy: 0.7642\n",
            "Epoch 718/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1670 - accuracy: 0.9409 - val_loss: 0.9387 - val_accuracy: 0.7480\n",
            "Epoch 719/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1319 - accuracy: 0.9430 - val_loss: 0.8901 - val_accuracy: 0.7480\n",
            "Epoch 720/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1258 - accuracy: 0.9572 - val_loss: 1.5222 - val_accuracy: 0.6585\n",
            "Epoch 721/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1992 - accuracy: 0.9287 - val_loss: 1.0082 - val_accuracy: 0.7805\n",
            "Epoch 722/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1314 - accuracy: 0.9470 - val_loss: 0.9677 - val_accuracy: 0.7724\n",
            "Epoch 723/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1258 - accuracy: 0.9491 - val_loss: 0.9523 - val_accuracy: 0.7480\n",
            "Epoch 724/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1228 - accuracy: 0.9532 - val_loss: 0.8830 - val_accuracy: 0.7480\n",
            "Epoch 725/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1572 - accuracy: 0.9369 - val_loss: 1.0282 - val_accuracy: 0.6341\n",
            "Epoch 726/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1690 - accuracy: 0.9409 - val_loss: 0.9724 - val_accuracy: 0.7480\n",
            "Epoch 727/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1515 - accuracy: 0.9369 - val_loss: 1.0016 - val_accuracy: 0.7480\n",
            "Epoch 728/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2161 - accuracy: 0.9104 - val_loss: 0.7882 - val_accuracy: 0.7886\n",
            "Epoch 729/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1928 - accuracy: 0.9145 - val_loss: 0.9197 - val_accuracy: 0.7642\n",
            "Epoch 730/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2204 - accuracy: 0.9043 - val_loss: 0.8762 - val_accuracy: 0.7561\n",
            "Epoch 731/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1914 - accuracy: 0.9308 - val_loss: 0.8238 - val_accuracy: 0.7561\n",
            "Epoch 732/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1144 - accuracy: 0.9593 - val_loss: 0.9303 - val_accuracy: 0.7561\n",
            "Epoch 733/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1235 - accuracy: 0.9552 - val_loss: 0.9239 - val_accuracy: 0.7480\n",
            "Epoch 734/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1071 - accuracy: 0.9613 - val_loss: 1.0935 - val_accuracy: 0.7724\n",
            "Epoch 735/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1343 - accuracy: 0.9409 - val_loss: 0.9953 - val_accuracy: 0.7480\n",
            "Epoch 736/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1286 - accuracy: 0.9511 - val_loss: 0.9044 - val_accuracy: 0.7398\n",
            "Epoch 737/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1199 - accuracy: 0.9511 - val_loss: 0.8881 - val_accuracy: 0.7317\n",
            "Epoch 738/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1358 - accuracy: 0.9389 - val_loss: 0.9011 - val_accuracy: 0.7967\n",
            "Epoch 739/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1270 - accuracy: 0.9511 - val_loss: 0.9691 - val_accuracy: 0.7642\n",
            "Epoch 740/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1269 - accuracy: 0.9511 - val_loss: 0.9476 - val_accuracy: 0.7561\n",
            "Epoch 741/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1529 - accuracy: 0.9409 - val_loss: 0.8344 - val_accuracy: 0.7480\n",
            "Epoch 742/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1265 - accuracy: 0.9511 - val_loss: 0.9370 - val_accuracy: 0.7886\n",
            "Epoch 743/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1679 - accuracy: 0.9287 - val_loss: 1.0438 - val_accuracy: 0.7967\n",
            "Epoch 744/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1175 - accuracy: 0.9532 - val_loss: 0.9727 - val_accuracy: 0.7561\n",
            "Epoch 745/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1661 - accuracy: 0.9287 - val_loss: 0.9226 - val_accuracy: 0.7805\n",
            "Epoch 746/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1390 - accuracy: 0.9470 - val_loss: 0.9894 - val_accuracy: 0.7724\n",
            "Epoch 747/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2153 - accuracy: 0.9165 - val_loss: 0.9403 - val_accuracy: 0.7642\n",
            "Epoch 748/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1290 - accuracy: 0.9470 - val_loss: 0.8959 - val_accuracy: 0.7967\n",
            "Epoch 749/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1356 - accuracy: 0.9389 - val_loss: 0.9679 - val_accuracy: 0.7561\n",
            "Epoch 750/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1793 - accuracy: 0.9246 - val_loss: 1.0035 - val_accuracy: 0.7642\n",
            "Epoch 751/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2749 - accuracy: 0.8961 - val_loss: 0.8814 - val_accuracy: 0.7724\n",
            "Epoch 752/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1156 - accuracy: 0.9511 - val_loss: 0.9562 - val_accuracy: 0.7886\n",
            "Epoch 753/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1702 - accuracy: 0.9389 - val_loss: 0.8531 - val_accuracy: 0.7317\n",
            "Epoch 754/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1540 - accuracy: 0.9308 - val_loss: 0.8392 - val_accuracy: 0.7724\n",
            "Epoch 755/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1505 - accuracy: 0.9369 - val_loss: 0.9537 - val_accuracy: 0.7317\n",
            "Epoch 756/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1061 - accuracy: 0.9593 - val_loss: 0.9603 - val_accuracy: 0.7642\n",
            "Epoch 757/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1065 - accuracy: 0.9593 - val_loss: 0.9605 - val_accuracy: 0.7642\n",
            "Epoch 758/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1173 - accuracy: 0.9552 - val_loss: 0.9405 - val_accuracy: 0.7236\n",
            "Epoch 759/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1145 - accuracy: 0.9511 - val_loss: 1.0571 - val_accuracy: 0.7724\n",
            "Epoch 760/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1383 - accuracy: 0.9511 - val_loss: 0.9434 - val_accuracy: 0.7642\n",
            "Epoch 761/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1055 - accuracy: 0.9572 - val_loss: 1.0330 - val_accuracy: 0.7805\n",
            "Epoch 762/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1596 - accuracy: 0.9348 - val_loss: 0.9847 - val_accuracy: 0.7480\n",
            "Epoch 763/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1309 - accuracy: 0.9409 - val_loss: 0.9974 - val_accuracy: 0.7642\n",
            "Epoch 764/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1097 - accuracy: 0.9552 - val_loss: 1.0154 - val_accuracy: 0.7480\n",
            "Epoch 765/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1037 - accuracy: 0.9593 - val_loss: 1.1308 - val_accuracy: 0.7398\n",
            "Epoch 766/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1722 - accuracy: 0.9328 - val_loss: 1.0751 - val_accuracy: 0.7724\n",
            "Epoch 767/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1282 - accuracy: 0.9430 - val_loss: 1.1668 - val_accuracy: 0.7317\n",
            "Epoch 768/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2277 - accuracy: 0.9267 - val_loss: 1.0684 - val_accuracy: 0.7642\n",
            "Epoch 769/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.3254 - accuracy: 0.8819 - val_loss: 0.8934 - val_accuracy: 0.7724\n",
            "Epoch 770/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1581 - accuracy: 0.9328 - val_loss: 1.0515 - val_accuracy: 0.7236\n",
            "Epoch 771/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1627 - accuracy: 0.9450 - val_loss: 0.9123 - val_accuracy: 0.7561\n",
            "Epoch 772/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1136 - accuracy: 0.9593 - val_loss: 0.9199 - val_accuracy: 0.7642\n",
            "Epoch 773/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1064 - accuracy: 0.9613 - val_loss: 0.9076 - val_accuracy: 0.7317\n",
            "Epoch 774/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1096 - accuracy: 0.9633 - val_loss: 0.8868 - val_accuracy: 0.7561\n",
            "Epoch 775/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1021 - accuracy: 0.9593 - val_loss: 0.9274 - val_accuracy: 0.7561\n",
            "Epoch 776/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1641 - accuracy: 0.9389 - val_loss: 0.8978 - val_accuracy: 0.7317\n",
            "Epoch 777/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1026 - accuracy: 0.9654 - val_loss: 0.9343 - val_accuracy: 0.7561\n",
            "Epoch 778/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1026 - accuracy: 0.9572 - val_loss: 1.1625 - val_accuracy: 0.7154\n",
            "Epoch 779/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1647 - accuracy: 0.9328 - val_loss: 1.0332 - val_accuracy: 0.6748\n",
            "Epoch 780/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1795 - accuracy: 0.9104 - val_loss: 0.9019 - val_accuracy: 0.7480\n",
            "Epoch 781/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1113 - accuracy: 0.9511 - val_loss: 1.0154 - val_accuracy: 0.7480\n",
            "Epoch 782/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1115 - accuracy: 0.9633 - val_loss: 1.0212 - val_accuracy: 0.7398\n",
            "Epoch 783/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1162 - accuracy: 0.9491 - val_loss: 0.9059 - val_accuracy: 0.7724\n",
            "Epoch 784/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1266 - accuracy: 0.9470 - val_loss: 0.8958 - val_accuracy: 0.7805\n",
            "Epoch 785/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1028 - accuracy: 0.9613 - val_loss: 0.9648 - val_accuracy: 0.7805\n",
            "Epoch 786/800\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2425 - accuracy: 0.9124 - val_loss: 1.0016 - val_accuracy: 0.7317\n",
            "Epoch 787/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1396 - accuracy: 0.9450 - val_loss: 0.9796 - val_accuracy: 0.7805\n",
            "Epoch 788/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1277 - accuracy: 0.9491 - val_loss: 0.9870 - val_accuracy: 0.7561\n",
            "Epoch 789/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1031 - accuracy: 0.9572 - val_loss: 1.0543 - val_accuracy: 0.7561\n",
            "Epoch 790/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1911 - accuracy: 0.9206 - val_loss: 1.0225 - val_accuracy: 0.7724\n",
            "Epoch 791/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1298 - accuracy: 0.9470 - val_loss: 1.0100 - val_accuracy: 0.7561\n",
            "Epoch 792/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1087 - accuracy: 0.9552 - val_loss: 0.9884 - val_accuracy: 0.7398\n",
            "Epoch 793/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1134 - accuracy: 0.9532 - val_loss: 1.1207 - val_accuracy: 0.7398\n",
            "Epoch 794/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0937 - accuracy: 0.9613 - val_loss: 1.0442 - val_accuracy: 0.7561\n",
            "Epoch 795/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1272 - accuracy: 0.9409 - val_loss: 0.9636 - val_accuracy: 0.7561\n",
            "Epoch 796/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1310 - accuracy: 0.9430 - val_loss: 1.0054 - val_accuracy: 0.7317\n",
            "Epoch 797/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.1188 - accuracy: 0.9572 - val_loss: 1.0473 - val_accuracy: 0.7642\n",
            "Epoch 798/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.0926 - accuracy: 0.9674 - val_loss: 1.0492 - val_accuracy: 0.7724\n",
            "Epoch 799/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2622 - accuracy: 0.8982 - val_loss: 0.9986 - val_accuracy: 0.7317\n",
            "Epoch 800/800\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.2746 - accuracy: 0.8982 - val_loss: 0.8772 - val_accuracy: 0.7561\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80o1i3fzZsA-"
      },
      "source": [
        "**11. Plot the training loss and accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt \n",
        "acc = hist.history['accuracy']\n",
        "val_acc = hist.history['val_accuracy']\n",
        "loss = hist.history['loss']\n",
        "val_loss = hist.history['val_loss']\n",
        " \n",
        "epochs = range(len(acc))\n",
        " \n",
        "plt.plot(epochs, acc, 'b', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.savefig('custom_trainvalacc.png')\n",
        "plt.figure()\n",
        " \n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        " \n",
        "#plt.show()\n",
        "plt.savefig('custom_trainvalloss.png')\n",
        "plt.figure()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "69dOEi6HAiXT",
        "outputId": "df8a3db7-7fd6-47d9-b367-a19a7e982b85"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8fUXoqeZvwf"
      },
      "source": [
        "**12. Evaluate the performance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wawHhkURYMLE",
        "outputId": "65df1921-9383-4faf-9190-e4654f977f86"
      },
      "source": [
        "res =model.evaluate(X_testing, Y_testing)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3527 - accuracy: 0.6494\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WCSw36oZyG_"
      },
      "source": [
        "**13. Predict on new datatset**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcE27mGFYo3G",
        "outputId": "6c0727b7-1d31-44c9-c53e-aa9274381a8e"
      },
      "source": [
        "test=X_testing[0]\n",
        "y_act=Y_testing[0]\n",
        "result=model.predict(test.reshape(1,8))\n",
        "result"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.9942894 , 0.00571059]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4RDC-ZHYqv_",
        "outputId": "40a6fae7-44dd-4d6f-d2de-5ca0be3b06eb"
      },
      "source": [
        "import numpy as np\n",
        "y_pred = np.round(result)\n",
        "print(\"Actual:\"+ str(y_act))\n",
        "print(\"Predicted:\"+str(y_pred))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual:[1. 0.]\n",
            "Predicted:[[1. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9mMqJtXYz2Q"
      },
      "source": [
        "**Reference:** - https://keras.io/"
      ]
    }
  ]
}